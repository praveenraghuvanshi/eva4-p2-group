{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main_suman.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3b3907b40b1647e7b2c2bb249625b2bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fd21419e3c64452ab3c2e213d098b661",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a0df46241bd84b738930420bcf1ad7cc",
              "IPY_MODEL_c54b0cb9d3fe49cbbc9c9f9794bd9034"
            ]
          }
        },
        "fd21419e3c64452ab3c2e213d098b661": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a0df46241bd84b738930420bcf1ad7cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_23ebc1e689b24023bc7e7ca9df001e47",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 111898327,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 111898327,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3921f881abbd45ea85cd8e2c7555f4e4"
          }
        },
        "c54b0cb9d3fe49cbbc9c9f9794bd9034": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5487289045a74f7886e139c5cc3ee81b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 107M/107M [00:08&lt;00:00, 13.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_384bcb98ea9f4fcaac821a1743ffc646"
          }
        },
        "23ebc1e689b24023bc7e7ca9df001e47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3921f881abbd45ea85cd8e2c7555f4e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5487289045a74f7886e139c5cc3ee81b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "384bcb98ea9f4fcaac821a1743ffc646": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hmGZGrKnNyT",
        "colab_type": "text"
      },
      "source": [
        "# Clone the repo\n",
        "##### Source is : https://towardsdatascience.com/finetune-a-facial-recognition-classifier-to-recognize-your-face-using-pytorch-d00a639d9a79"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wt0IrvVpyya",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "09dc8cdb-37bc-485d-b402-8e367fbf363d"
      },
      "source": [
        "!pip install torch==1.5.1+cu92 torchvision==0.6.1+cu92 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Requirement already satisfied: torch==1.5.1+cu92 in /usr/local/lib/python3.6/dist-packages (1.5.1+cu92)\n",
            "Requirement already satisfied: torchvision==0.6.1+cu92 in /usr/local/lib/python3.6/dist-packages (0.6.1+cu92)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu92) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu92) (0.16.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.6.1+cu92) (7.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7khiqC2lUof",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os \n",
        "#os.chdir('/content/drive/My Drive/EVA4/phase2/s4_faceRecognition')\n",
        "#!git clone https://github.com/timesler/facenet-pytorch.git"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qd9PnfginUQe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/drive/My Drive/EVA4/phase2/s4_faceRecognition/detectMyFace_project')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-i9XEYFk8Jl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import nn, optim, as_tensor\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.nn.init import *\n",
        "from torchvision import transforms, utils, datasets, models\n",
        "from models.inception_resnet_v1 import InceptionResnetV1\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from pdb import set_trace\n",
        "import time\n",
        "import copy\n",
        "from pathlib import Path\n",
        "import os\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from skimage import io, transform\n",
        "from tqdm import trange, tqdm\n",
        "import csv\n",
        "import glob\n",
        "import dlib\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzIPdeY4nQzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "data_dir = 'data/test_me_aligned_bkp'\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                          data_transforms[x])\n",
        "                  for x in ['train', 'val']}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
        "                                              batch_size=8, \n",
        "                                             shuffle=True)\n",
        "              for x in ['train', 'val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train','val']}\n",
        "class_names = image_datasets['train'].classes\n",
        "class_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3eeIiDvnzsN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "# Get a batch of training data\n",
        "inputs, classes = next(iter(dataloaders['train']))\n",
        "# Make a grid from batch\n",
        "out = utils.make_grid(inputs)\n",
        "imshow(out, title=[class_names[x] for x in classes])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyawFmRqxGc6",
        "colab_type": "text"
      },
      "source": [
        "# Get pretrained ResNet on VGGFace2 dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbMOMtXZxbXu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxt3Eu8Qw_Xj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "3b3907b40b1647e7b2c2bb249625b2bd",
            "fd21419e3c64452ab3c2e213d098b661",
            "a0df46241bd84b738930420bcf1ad7cc",
            "c54b0cb9d3fe49cbbc9c9f9794bd9034",
            "23ebc1e689b24023bc7e7ca9df001e47",
            "3921f881abbd45ea85cd8e2c7555f4e4",
            "5487289045a74f7886e139c5cc3ee81b",
            "384bcb98ea9f4fcaac821a1743ffc646"
          ]
        },
        "outputId": "a80c931c-409e-477a-d39b-74eab9c8469c"
      },
      "source": [
        "from models.inception_resnet_v1 import InceptionResnetV1\n",
        "print('Running on device: {}'.format(device))\n",
        "model_ft = InceptionResnetV1(pretrained='vggface2', classify=False, num_classes = len(class_names))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on device: cuda\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3b3907b40b1647e7b2c2bb249625b2bd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=111898327.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Csv0ALVCyBIm",
        "colab_type": "text"
      },
      "source": [
        "# Freeze early layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sG41FrZSyMnV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "outputId": "3b9cb53c-29c4-4788-d0e4-a338fd68aeff"
      },
      "source": [
        "list(model_ft.children())[-6:]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Block8(\n",
              "   (branch0): BasicConv2d(\n",
              "     (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "     (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "     (relu): ReLU()\n",
              "   )\n",
              "   (branch1): Sequential(\n",
              "     (0): BasicConv2d(\n",
              "       (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "       (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "       (relu): ReLU()\n",
              "     )\n",
              "     (1): BasicConv2d(\n",
              "       (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "       (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "       (relu): ReLU()\n",
              "     )\n",
              "     (2): BasicConv2d(\n",
              "       (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "       (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "       (relu): ReLU()\n",
              "     )\n",
              "   )\n",
              "   (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              " ),\n",
              " AdaptiveAvgPool2d(output_size=1),\n",
              " Dropout(p=0.6, inplace=False),\n",
              " Linear(in_features=1792, out_features=512, bias=False),\n",
              " BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True),\n",
              " Linear(in_features=512, out_features=8631, bias=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NI-cqCH9yb0U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "564f3613-af56-4b12-b97c-b1e1864dd58e"
      },
      "source": [
        "layer_list = list(model_ft.children())[-5:] # all final layers\n",
        "layer_list"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[AdaptiveAvgPool2d(output_size=1),\n",
              " Dropout(p=0.6, inplace=False),\n",
              " Linear(in_features=1792, out_features=512, bias=False),\n",
              " BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True),\n",
              " Linear(in_features=512, out_features=8631, bias=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZadG2-jFz_yV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_ft = nn.Sequential(*list(model_ft.children())[:-5])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zMTMcXj26a8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0533d881-e70b-44c2-b473-854a7778c18f"
      },
      "source": [
        "model_ft"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): BasicConv2d(\n",
              "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (1): BasicConv2d(\n",
              "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (2): BasicConv2d(\n",
              "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (4): BasicConv2d(\n",
              "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (5): BasicConv2d(\n",
              "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (6): BasicConv2d(\n",
              "    (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "    (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (7): Sequential(\n",
              "    (0): Block35(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (branch2): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (1): Block35(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (branch2): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (2): Block35(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (branch2): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (3): Block35(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (branch2): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (4): Block35(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (branch2): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (8): Mixed_6a(\n",
              "    (branch0): BasicConv2d(\n",
              "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (branch1): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (2): BasicConv2d(\n",
              "        (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (branch2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (9): Sequential(\n",
              "    (0): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (1): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (2): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (3): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (4): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (5): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (6): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (7): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (8): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (9): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (10): Mixed_7a(\n",
              "    (branch0): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (branch1): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (2): BasicConv2d(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (branch3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (11): Sequential(\n",
              "    (0): Block8(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (1): Block8(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (2): Block8(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (3): Block8(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (4): Block8(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (12): Block8(\n",
              "    (branch0): BasicConv2d(\n",
              "      (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (branch1): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (2): BasicConv2d(\n",
              "        (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEFzXz2B0sQU",
        "colab_type": "text"
      },
      "source": [
        "## If training just final layers:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuyFWk0Z0SIG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for param in model_ft.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwxymZ2-0pi3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Flatten, self).__init__()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return x\n",
        "class normalize(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(normalize, self).__init__()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.normalize(x, p=2, dim=1)\n",
        "        return x"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCDE1MHP1HMn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_ft.avgpool_1a = nn.AdaptiveAvgPool2d(output_size=1)\n",
        "model_ft.last_linear = nn.Sequential(\n",
        "    Flatten(),\n",
        "    nn.Linear(in_features=1792, out_features=512, bias=False),\n",
        "    normalize()\n",
        ")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxAjQwzq2O8W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "6fc13a79-0bac-4761-a4df-571ceccdafb1"
      },
      "source": [
        "layer_list"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[AdaptiveAvgPool2d(output_size=1),\n",
              " Dropout(p=0.6, inplace=False),\n",
              " Linear(in_features=1792, out_features=512, bias=False),\n",
              " BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True),\n",
              " Linear(in_features=512, out_features=8631, bias=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8BMerqf5Ngv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_ft.logits = nn.Linear(512, len(class_names))\n",
        "model_ft.softmax = nn.Softmax(dim=1)\n",
        "model_ft = model_ft.to(device)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00JC48s-6bNd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "191db4e3-4279-4282-9238-edf4e4e72cc6"
      },
      "source": [
        "model_ft"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): BasicConv2d(\n",
              "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (1): BasicConv2d(\n",
              "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (2): BasicConv2d(\n",
              "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (4): BasicConv2d(\n",
              "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (5): BasicConv2d(\n",
              "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (6): BasicConv2d(\n",
              "    (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "    (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (7): Sequential(\n",
              "    (0): Block35(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (branch2): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (1): Block35(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (branch2): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (2): Block35(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (branch2): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (3): Block35(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (branch2): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (4): Block35(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (branch2): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (8): Mixed_6a(\n",
              "    (branch0): BasicConv2d(\n",
              "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (branch1): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (2): BasicConv2d(\n",
              "        (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (branch2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (9): Sequential(\n",
              "    (0): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (1): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (2): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (3): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (4): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (5): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (6): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (7): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (8): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (9): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (10): Mixed_7a(\n",
              "    (branch0): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (branch1): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (2): BasicConv2d(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (branch3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (11): Sequential(\n",
              "    (0): Block8(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (1): Block8(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (2): Block8(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (3): Block8(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (4): Block8(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (12): Block8(\n",
              "    (branch0): BasicConv2d(\n",
              "      (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (branch1): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (2): BasicConv2d(\n",
              "        (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              "  (avgpool_1a): AdaptiveAvgPool2d(output_size=1)\n",
              "  (last_linear): Sequential(\n",
              "    (0): Flatten()\n",
              "    (1): Linear(in_features=1792, out_features=512, bias=False)\n",
              "    (2): normalize()\n",
              "  )\n",
              "  (logits): Linear(in_features=512, out_features=4, bias=True)\n",
              "  (softmax): Softmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgPWCBpL6ejO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=1e-2, momentum=0.9)\n",
        "# Decay LR by a factor of *gamma* every *step_size* epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPFA5xsC6yzm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, criterion, optimizer, scheduler,\n",
        "                num_epochs=25):\n",
        "    since = time.time()\n",
        "    FT_losses = []\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "    # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                        #scheduler.step()\n",
        "                \n",
        "                FT_losses.append(loss.item())\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, FT_losses"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCkYj6p_61kf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "50705c68-9420-4b41-9a4d-6e0096f35a29"
      },
      "source": [
        "model_ft, FT_losses = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=500)\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"FRT Loss During Training\")\n",
        "plt.plot(FT_losses, label=\"FT loss\")\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/499\n",
            "----------\n",
            "train Loss: 1.3870 Acc: 0.1316\n",
            "val Loss: 1.3865 Acc: 0.1765\n",
            "Epoch 1/499\n",
            "----------\n",
            "train Loss: 1.3816 Acc: 0.3947\n",
            "val Loss: 1.3790 Acc: 0.5882\n",
            "Epoch 2/499\n",
            "----------\n",
            "train Loss: 1.3726 Acc: 0.8684\n",
            "val Loss: 1.3693 Acc: 1.0000\n",
            "Epoch 3/499\n",
            "----------\n",
            "train Loss: 1.3619 Acc: 1.0000\n",
            "val Loss: 1.3584 Acc: 1.0000\n",
            "Epoch 4/499\n",
            "----------\n",
            "train Loss: 1.3494 Acc: 1.0000\n",
            "val Loss: 1.3461 Acc: 1.0000\n",
            "Epoch 5/499\n",
            "----------\n",
            "train Loss: 1.3392 Acc: 1.0000\n",
            "val Loss: 1.3343 Acc: 1.0000\n",
            "Epoch 6/499\n",
            "----------\n",
            "train Loss: 1.3258 Acc: 1.0000\n",
            "val Loss: 1.3226 Acc: 1.0000\n",
            "Epoch 7/499\n",
            "----------\n",
            "train Loss: 1.3150 Acc: 1.0000\n",
            "val Loss: 1.3111 Acc: 1.0000\n",
            "Epoch 8/499\n",
            "----------\n",
            "train Loss: 1.3064 Acc: 1.0000\n",
            "val Loss: 1.2995 Acc: 1.0000\n",
            "Epoch 9/499\n",
            "----------\n",
            "train Loss: 1.2900 Acc: 1.0000\n",
            "val Loss: 1.2893 Acc: 1.0000\n",
            "Epoch 10/499\n",
            "----------\n",
            "train Loss: 1.2749 Acc: 1.0000\n",
            "val Loss: 1.2792 Acc: 1.0000\n",
            "Epoch 11/499\n",
            "----------\n",
            "train Loss: 1.2647 Acc: 1.0000\n",
            "val Loss: 1.2688 Acc: 1.0000\n",
            "Epoch 12/499\n",
            "----------\n",
            "train Loss: 1.2625 Acc: 1.0000\n",
            "val Loss: 1.2585 Acc: 1.0000\n",
            "Epoch 13/499\n",
            "----------\n",
            "train Loss: 1.2450 Acc: 1.0000\n",
            "val Loss: 1.2483 Acc: 1.0000\n",
            "Epoch 14/499\n",
            "----------\n",
            "train Loss: 1.2453 Acc: 1.0000\n",
            "val Loss: 1.2385 Acc: 1.0000\n",
            "Epoch 15/499\n",
            "----------\n",
            "train Loss: 1.2276 Acc: 1.0000\n",
            "val Loss: 1.2289 Acc: 1.0000\n",
            "Epoch 16/499\n",
            "----------\n",
            "train Loss: 1.2235 Acc: 0.9737\n",
            "val Loss: 1.2188 Acc: 1.0000\n",
            "Epoch 17/499\n",
            "----------\n",
            "train Loss: 1.2110 Acc: 1.0000\n",
            "val Loss: 1.2096 Acc: 1.0000\n",
            "Epoch 18/499\n",
            "----------\n",
            "train Loss: 1.2128 Acc: 1.0000\n",
            "val Loss: 1.2002 Acc: 1.0000\n",
            "Epoch 19/499\n",
            "----------\n",
            "train Loss: 1.1830 Acc: 1.0000\n",
            "val Loss: 1.1907 Acc: 1.0000\n",
            "Epoch 20/499\n",
            "----------\n",
            "train Loss: 1.1816 Acc: 1.0000\n",
            "val Loss: 1.1804 Acc: 1.0000\n",
            "Epoch 21/499\n",
            "----------\n",
            "train Loss: 1.1644 Acc: 1.0000\n",
            "val Loss: 1.1707 Acc: 1.0000\n",
            "Epoch 22/499\n",
            "----------\n",
            "train Loss: 1.1738 Acc: 0.9737\n",
            "val Loss: 1.1628 Acc: 1.0000\n",
            "Epoch 23/499\n",
            "----------\n",
            "train Loss: 1.1538 Acc: 1.0000\n",
            "val Loss: 1.1521 Acc: 1.0000\n",
            "Epoch 24/499\n",
            "----------\n",
            "train Loss: 1.1376 Acc: 1.0000\n",
            "val Loss: 1.1431 Acc: 1.0000\n",
            "Epoch 25/499\n",
            "----------\n",
            "train Loss: 1.1471 Acc: 0.9474\n",
            "val Loss: 1.1341 Acc: 1.0000\n",
            "Epoch 26/499\n",
            "----------\n",
            "train Loss: 1.1223 Acc: 1.0000\n",
            "val Loss: 1.1248 Acc: 1.0000\n",
            "Epoch 27/499\n",
            "----------\n",
            "train Loss: 1.1221 Acc: 1.0000\n",
            "val Loss: 1.1161 Acc: 1.0000\n",
            "Epoch 28/499\n",
            "----------\n",
            "train Loss: 1.1067 Acc: 1.0000\n",
            "val Loss: 1.1071 Acc: 1.0000\n",
            "Epoch 29/499\n",
            "----------\n",
            "train Loss: 1.1001 Acc: 1.0000\n",
            "val Loss: 1.0979 Acc: 1.0000\n",
            "Epoch 30/499\n",
            "----------\n",
            "train Loss: 1.0962 Acc: 1.0000\n",
            "val Loss: 1.0897 Acc: 1.0000\n",
            "Epoch 31/499\n",
            "----------\n",
            "train Loss: 1.0841 Acc: 1.0000\n",
            "val Loss: 1.0821 Acc: 1.0000\n",
            "Epoch 32/499\n",
            "----------\n",
            "train Loss: 1.0744 Acc: 1.0000\n",
            "val Loss: 1.0733 Acc: 1.0000\n",
            "Epoch 33/499\n",
            "----------\n",
            "train Loss: 1.0591 Acc: 1.0000\n",
            "val Loss: 1.0648 Acc: 1.0000\n",
            "Epoch 34/499\n",
            "----------\n",
            "train Loss: 1.0550 Acc: 0.9737\n",
            "val Loss: 1.0574 Acc: 1.0000\n",
            "Epoch 35/499\n",
            "----------\n",
            "train Loss: 1.0402 Acc: 1.0000\n",
            "val Loss: 1.0499 Acc: 1.0000\n",
            "Epoch 36/499\n",
            "----------\n",
            "train Loss: 1.0414 Acc: 1.0000\n",
            "val Loss: 1.0427 Acc: 1.0000\n",
            "Epoch 37/499\n",
            "----------\n",
            "train Loss: 1.0426 Acc: 0.9211\n",
            "val Loss: 1.0360 Acc: 1.0000\n",
            "Epoch 38/499\n",
            "----------\n",
            "train Loss: 1.0475 Acc: 0.9737\n",
            "val Loss: 1.0286 Acc: 1.0000\n",
            "Epoch 39/499\n",
            "----------\n",
            "train Loss: 1.0188 Acc: 1.0000\n",
            "val Loss: 1.0217 Acc: 1.0000\n",
            "Epoch 40/499\n",
            "----------\n",
            "train Loss: 1.0045 Acc: 1.0000\n",
            "val Loss: 1.0146 Acc: 1.0000\n",
            "Epoch 41/499\n",
            "----------\n",
            "train Loss: 1.0326 Acc: 1.0000\n",
            "val Loss: 1.0081 Acc: 1.0000\n",
            "Epoch 42/499\n",
            "----------\n",
            "train Loss: 1.0030 Acc: 1.0000\n",
            "val Loss: 1.0019 Acc: 1.0000\n",
            "Epoch 43/499\n",
            "----------\n",
            "train Loss: 1.0016 Acc: 1.0000\n",
            "val Loss: 0.9961 Acc: 1.0000\n",
            "Epoch 44/499\n",
            "----------\n",
            "train Loss: 1.0031 Acc: 1.0000\n",
            "val Loss: 0.9907 Acc: 1.0000\n",
            "Epoch 45/499\n",
            "----------\n",
            "train Loss: 0.9688 Acc: 1.0000\n",
            "val Loss: 0.9853 Acc: 1.0000\n",
            "Epoch 46/499\n",
            "----------\n",
            "train Loss: 0.9757 Acc: 1.0000\n",
            "val Loss: 0.9795 Acc: 1.0000\n",
            "Epoch 47/499\n",
            "----------\n",
            "train Loss: 0.9902 Acc: 1.0000\n",
            "val Loss: 0.9744 Acc: 1.0000\n",
            "Epoch 48/499\n",
            "----------\n",
            "train Loss: 0.9641 Acc: 1.0000\n",
            "val Loss: 0.9694 Acc: 1.0000\n",
            "Epoch 49/499\n",
            "----------\n",
            "train Loss: 0.9605 Acc: 1.0000\n",
            "val Loss: 0.9636 Acc: 1.0000\n",
            "Epoch 50/499\n",
            "----------\n",
            "train Loss: 0.9562 Acc: 1.0000\n",
            "val Loss: 0.9587 Acc: 1.0000\n",
            "Epoch 51/499\n",
            "----------\n",
            "train Loss: 0.9611 Acc: 1.0000\n",
            "val Loss: 0.9541 Acc: 1.0000\n",
            "Epoch 52/499\n",
            "----------\n",
            "train Loss: 0.9480 Acc: 1.0000\n",
            "val Loss: 0.9489 Acc: 1.0000\n",
            "Epoch 53/499\n",
            "----------\n",
            "train Loss: 0.9618 Acc: 0.9737\n",
            "val Loss: 0.9447 Acc: 1.0000\n",
            "Epoch 54/499\n",
            "----------\n",
            "train Loss: 0.9563 Acc: 1.0000\n",
            "val Loss: 0.9399 Acc: 1.0000\n",
            "Epoch 55/499\n",
            "----------\n",
            "train Loss: 0.9450 Acc: 1.0000\n",
            "val Loss: 0.9356 Acc: 1.0000\n",
            "Epoch 56/499\n",
            "----------\n",
            "train Loss: 0.9290 Acc: 1.0000\n",
            "val Loss: 0.9313 Acc: 1.0000\n",
            "Epoch 57/499\n",
            "----------\n",
            "train Loss: 0.9367 Acc: 1.0000\n",
            "val Loss: 0.9277 Acc: 1.0000\n",
            "Epoch 58/499\n",
            "----------\n",
            "train Loss: 0.9271 Acc: 1.0000\n",
            "val Loss: 0.9241 Acc: 1.0000\n",
            "Epoch 59/499\n",
            "----------\n",
            "train Loss: 0.9372 Acc: 1.0000\n",
            "val Loss: 0.9204 Acc: 1.0000\n",
            "Epoch 60/499\n",
            "----------\n",
            "train Loss: 0.9144 Acc: 1.0000\n",
            "val Loss: 0.9163 Acc: 1.0000\n",
            "Epoch 61/499\n",
            "----------\n",
            "train Loss: 0.9094 Acc: 1.0000\n",
            "val Loss: 0.9131 Acc: 1.0000\n",
            "Epoch 62/499\n",
            "----------\n",
            "train Loss: 0.9104 Acc: 1.0000\n",
            "val Loss: 0.9098 Acc: 1.0000\n",
            "Epoch 63/499\n",
            "----------\n",
            "train Loss: 0.9170 Acc: 1.0000\n",
            "val Loss: 0.9066 Acc: 1.0000\n",
            "Epoch 64/499\n",
            "----------\n",
            "train Loss: 0.8878 Acc: 1.0000\n",
            "val Loss: 0.9032 Acc: 1.0000\n",
            "Epoch 65/499\n",
            "----------\n",
            "train Loss: 0.8971 Acc: 1.0000\n",
            "val Loss: 0.9001 Acc: 1.0000\n",
            "Epoch 66/499\n",
            "----------\n",
            "train Loss: 0.8903 Acc: 1.0000\n",
            "val Loss: 0.8971 Acc: 1.0000\n",
            "Epoch 67/499\n",
            "----------\n",
            "train Loss: 0.8917 Acc: 1.0000\n",
            "val Loss: 0.8944 Acc: 1.0000\n",
            "Epoch 68/499\n",
            "----------\n",
            "train Loss: 0.8769 Acc: 1.0000\n",
            "val Loss: 0.8921 Acc: 1.0000\n",
            "Epoch 69/499\n",
            "----------\n",
            "train Loss: 0.8849 Acc: 1.0000\n",
            "val Loss: 0.8891 Acc: 1.0000\n",
            "Epoch 70/499\n",
            "----------\n",
            "train Loss: 0.8813 Acc: 1.0000\n",
            "val Loss: 0.8867 Acc: 1.0000\n",
            "Epoch 71/499\n",
            "----------\n",
            "train Loss: 0.8777 Acc: 1.0000\n",
            "val Loss: 0.8840 Acc: 1.0000\n",
            "Epoch 72/499\n",
            "----------\n",
            "train Loss: 0.8792 Acc: 1.0000\n",
            "val Loss: 0.8813 Acc: 1.0000\n",
            "Epoch 73/499\n",
            "----------\n",
            "train Loss: 0.8726 Acc: 1.0000\n",
            "val Loss: 0.8787 Acc: 1.0000\n",
            "Epoch 74/499\n",
            "----------\n",
            "train Loss: 0.8647 Acc: 1.0000\n",
            "val Loss: 0.8762 Acc: 1.0000\n",
            "Epoch 75/499\n",
            "----------\n",
            "train Loss: 0.8624 Acc: 1.0000\n",
            "val Loss: 0.8745 Acc: 1.0000\n",
            "Epoch 76/499\n",
            "----------\n",
            "train Loss: 0.8811 Acc: 1.0000\n",
            "val Loss: 0.8722 Acc: 1.0000\n",
            "Epoch 77/499\n",
            "----------\n",
            "train Loss: 0.8816 Acc: 1.0000\n",
            "val Loss: 0.8703 Acc: 1.0000\n",
            "Epoch 78/499\n",
            "----------\n",
            "train Loss: 0.8620 Acc: 1.0000\n",
            "val Loss: 0.8682 Acc: 1.0000\n",
            "Epoch 79/499\n",
            "----------\n",
            "train Loss: 0.8708 Acc: 1.0000\n",
            "val Loss: 0.8662 Acc: 1.0000\n",
            "Epoch 80/499\n",
            "----------\n",
            "train Loss: 0.8561 Acc: 1.0000\n",
            "val Loss: 0.8635 Acc: 1.0000\n",
            "Epoch 81/499\n",
            "----------\n",
            "train Loss: 0.8496 Acc: 1.0000\n",
            "val Loss: 0.8624 Acc: 1.0000\n",
            "Epoch 82/499\n",
            "----------\n",
            "train Loss: 0.8545 Acc: 1.0000\n",
            "val Loss: 0.8605 Acc: 1.0000\n",
            "Epoch 83/499\n",
            "----------\n",
            "train Loss: 0.8454 Acc: 1.0000\n",
            "val Loss: 0.8583 Acc: 1.0000\n",
            "Epoch 84/499\n",
            "----------\n",
            "train Loss: 0.8429 Acc: 1.0000\n",
            "val Loss: 0.8561 Acc: 1.0000\n",
            "Epoch 85/499\n",
            "----------\n",
            "train Loss: 0.8597 Acc: 1.0000\n",
            "val Loss: 0.8544 Acc: 1.0000\n",
            "Epoch 86/499\n",
            "----------\n",
            "train Loss: 0.8642 Acc: 1.0000\n",
            "val Loss: 0.8530 Acc: 1.0000\n",
            "Epoch 87/499\n",
            "----------\n",
            "train Loss: 0.8380 Acc: 1.0000\n",
            "val Loss: 0.8517 Acc: 1.0000\n",
            "Epoch 88/499\n",
            "----------\n",
            "train Loss: 0.8556 Acc: 1.0000\n",
            "val Loss: 0.8504 Acc: 1.0000\n",
            "Epoch 89/499\n",
            "----------\n",
            "train Loss: 0.8466 Acc: 1.0000\n",
            "val Loss: 0.8483 Acc: 1.0000\n",
            "Epoch 90/499\n",
            "----------\n",
            "train Loss: 0.8457 Acc: 1.0000\n",
            "val Loss: 0.8469 Acc: 1.0000\n",
            "Epoch 91/499\n",
            "----------\n",
            "train Loss: 0.8433 Acc: 1.0000\n",
            "val Loss: 0.8452 Acc: 1.0000\n",
            "Epoch 92/499\n",
            "----------\n",
            "train Loss: 0.8391 Acc: 1.0000\n",
            "val Loss: 0.8440 Acc: 1.0000\n",
            "Epoch 93/499\n",
            "----------\n",
            "train Loss: 0.8376 Acc: 1.0000\n",
            "val Loss: 0.8431 Acc: 1.0000\n",
            "Epoch 94/499\n",
            "----------\n",
            "train Loss: 0.8420 Acc: 1.0000\n",
            "val Loss: 0.8414 Acc: 1.0000\n",
            "Epoch 95/499\n",
            "----------\n",
            "train Loss: 0.8298 Acc: 1.0000\n",
            "val Loss: 0.8401 Acc: 1.0000\n",
            "Epoch 96/499\n",
            "----------\n",
            "train Loss: 0.8295 Acc: 1.0000\n",
            "val Loss: 0.8389 Acc: 1.0000\n",
            "Epoch 97/499\n",
            "----------\n",
            "train Loss: 0.8300 Acc: 1.0000\n",
            "val Loss: 0.8380 Acc: 1.0000\n",
            "Epoch 98/499\n",
            "----------\n",
            "train Loss: 0.8327 Acc: 1.0000\n",
            "val Loss: 0.8366 Acc: 1.0000\n",
            "Epoch 99/499\n",
            "----------\n",
            "train Loss: 0.8261 Acc: 1.0000\n",
            "val Loss: 0.8355 Acc: 1.0000\n",
            "Epoch 100/499\n",
            "----------\n",
            "train Loss: 0.8392 Acc: 1.0000\n",
            "val Loss: 0.8345 Acc: 1.0000\n",
            "Epoch 101/499\n",
            "----------\n",
            "train Loss: 0.8289 Acc: 1.0000\n",
            "val Loss: 0.8331 Acc: 1.0000\n",
            "Epoch 102/499\n",
            "----------\n",
            "train Loss: 0.8322 Acc: 1.0000\n",
            "val Loss: 0.8319 Acc: 1.0000\n",
            "Epoch 103/499\n",
            "----------\n",
            "train Loss: 0.8316 Acc: 1.0000\n",
            "val Loss: 0.8310 Acc: 1.0000\n",
            "Epoch 104/499\n",
            "----------\n",
            "train Loss: 0.8268 Acc: 1.0000\n",
            "val Loss: 0.8304 Acc: 1.0000\n",
            "Epoch 105/499\n",
            "----------\n",
            "train Loss: 0.8169 Acc: 1.0000\n",
            "val Loss: 0.8290 Acc: 1.0000\n",
            "Epoch 106/499\n",
            "----------\n",
            "train Loss: 0.8161 Acc: 1.0000\n",
            "val Loss: 0.8283 Acc: 1.0000\n",
            "Epoch 107/499\n",
            "----------\n",
            "train Loss: 0.8418 Acc: 1.0000\n",
            "val Loss: 0.8269 Acc: 1.0000\n",
            "Epoch 108/499\n",
            "----------\n",
            "train Loss: 0.8270 Acc: 1.0000\n",
            "val Loss: 0.8257 Acc: 1.0000\n",
            "Epoch 109/499\n",
            "----------\n",
            "train Loss: 0.8322 Acc: 1.0000\n",
            "val Loss: 0.8249 Acc: 1.0000\n",
            "Epoch 110/499\n",
            "----------\n",
            "train Loss: 0.8185 Acc: 1.0000\n",
            "val Loss: 0.8241 Acc: 1.0000\n",
            "Epoch 111/499\n",
            "----------\n",
            "train Loss: 0.8165 Acc: 1.0000\n",
            "val Loss: 0.8230 Acc: 1.0000\n",
            "Epoch 112/499\n",
            "----------\n",
            "train Loss: 0.8250 Acc: 1.0000\n",
            "val Loss: 0.8221 Acc: 1.0000\n",
            "Epoch 113/499\n",
            "----------\n",
            "train Loss: 0.8180 Acc: 1.0000\n",
            "val Loss: 0.8213 Acc: 1.0000\n",
            "Epoch 114/499\n",
            "----------\n",
            "train Loss: 0.8108 Acc: 1.0000\n",
            "val Loss: 0.8205 Acc: 1.0000\n",
            "Epoch 115/499\n",
            "----------\n",
            "train Loss: 0.8162 Acc: 1.0000\n",
            "val Loss: 0.8200 Acc: 1.0000\n",
            "Epoch 116/499\n",
            "----------\n",
            "train Loss: 0.8165 Acc: 1.0000\n",
            "val Loss: 0.8192 Acc: 1.0000\n",
            "Epoch 117/499\n",
            "----------\n",
            "train Loss: 0.8160 Acc: 1.0000\n",
            "val Loss: 0.8181 Acc: 1.0000\n",
            "Epoch 118/499\n",
            "----------\n",
            "train Loss: 0.8272 Acc: 1.0000\n",
            "val Loss: 0.8172 Acc: 1.0000\n",
            "Epoch 119/499\n",
            "----------\n",
            "train Loss: 0.8116 Acc: 1.0000\n",
            "val Loss: 0.8166 Acc: 1.0000\n",
            "Epoch 120/499\n",
            "----------\n",
            "train Loss: 0.8131 Acc: 1.0000\n",
            "val Loss: 0.8160 Acc: 1.0000\n",
            "Epoch 121/499\n",
            "----------\n",
            "train Loss: 0.8110 Acc: 1.0000\n",
            "val Loss: 0.8158 Acc: 1.0000\n",
            "Epoch 122/499\n",
            "----------\n",
            "train Loss: 0.8028 Acc: 1.0000\n",
            "val Loss: 0.8149 Acc: 1.0000\n",
            "Epoch 123/499\n",
            "----------\n",
            "train Loss: 0.8096 Acc: 1.0000\n",
            "val Loss: 0.8146 Acc: 1.0000\n",
            "Epoch 124/499\n",
            "----------\n",
            "train Loss: 0.8065 Acc: 1.0000\n",
            "val Loss: 0.8134 Acc: 1.0000\n",
            "Epoch 125/499\n",
            "----------\n",
            "train Loss: 0.8067 Acc: 1.0000\n",
            "val Loss: 0.8126 Acc: 1.0000\n",
            "Epoch 126/499\n",
            "----------\n",
            "train Loss: 0.8081 Acc: 1.0000\n",
            "val Loss: 0.8120 Acc: 1.0000\n",
            "Epoch 127/499\n",
            "----------\n",
            "train Loss: 0.8045 Acc: 1.0000\n",
            "val Loss: 0.8113 Acc: 1.0000\n",
            "Epoch 128/499\n",
            "----------\n",
            "train Loss: 0.8111 Acc: 1.0000\n",
            "val Loss: 0.8112 Acc: 1.0000\n",
            "Epoch 129/499\n",
            "----------\n",
            "train Loss: 0.8003 Acc: 1.0000\n",
            "val Loss: 0.8108 Acc: 1.0000\n",
            "Epoch 130/499\n",
            "----------\n",
            "train Loss: 0.7984 Acc: 1.0000\n",
            "val Loss: 0.8100 Acc: 1.0000\n",
            "Epoch 131/499\n",
            "----------\n",
            "train Loss: 0.8097 Acc: 1.0000\n",
            "val Loss: 0.8104 Acc: 1.0000\n",
            "Epoch 132/499\n",
            "----------\n",
            "train Loss: 0.8032 Acc: 1.0000\n",
            "val Loss: 0.8093 Acc: 1.0000\n",
            "Epoch 133/499\n",
            "----------\n",
            "train Loss: 0.8046 Acc: 1.0000\n",
            "val Loss: 0.8087 Acc: 1.0000\n",
            "Epoch 134/499\n",
            "----------\n",
            "train Loss: 0.7971 Acc: 1.0000\n",
            "val Loss: 0.8078 Acc: 1.0000\n",
            "Epoch 135/499\n",
            "----------\n",
            "train Loss: 0.7997 Acc: 1.0000\n",
            "val Loss: 0.8063 Acc: 1.0000\n",
            "Epoch 136/499\n",
            "----------\n",
            "train Loss: 0.7942 Acc: 1.0000\n",
            "val Loss: 0.8059 Acc: 1.0000\n",
            "Epoch 137/499\n",
            "----------\n",
            "train Loss: 0.8029 Acc: 1.0000\n",
            "val Loss: 0.8055 Acc: 1.0000\n",
            "Epoch 138/499\n",
            "----------\n",
            "train Loss: 0.8086 Acc: 1.0000\n",
            "val Loss: 0.8058 Acc: 1.0000\n",
            "Epoch 139/499\n",
            "----------\n",
            "train Loss: 0.7993 Acc: 1.0000\n",
            "val Loss: 0.8055 Acc: 1.0000\n",
            "Epoch 140/499\n",
            "----------\n",
            "train Loss: 0.7922 Acc: 1.0000\n",
            "val Loss: 0.8048 Acc: 1.0000\n",
            "Epoch 141/499\n",
            "----------\n",
            "train Loss: 0.8017 Acc: 1.0000\n",
            "val Loss: 0.8035 Acc: 1.0000\n",
            "Epoch 142/499\n",
            "----------\n",
            "train Loss: 0.7987 Acc: 1.0000\n",
            "val Loss: 0.8027 Acc: 1.0000\n",
            "Epoch 143/499\n",
            "----------\n",
            "train Loss: 0.7995 Acc: 1.0000\n",
            "val Loss: 0.8022 Acc: 1.0000\n",
            "Epoch 144/499\n",
            "----------\n",
            "train Loss: 0.7950 Acc: 1.0000\n",
            "val Loss: 0.8021 Acc: 1.0000\n",
            "Epoch 145/499\n",
            "----------\n",
            "train Loss: 0.7994 Acc: 1.0000\n",
            "val Loss: 0.8015 Acc: 1.0000\n",
            "Epoch 146/499\n",
            "----------\n",
            "train Loss: 0.7980 Acc: 1.0000\n",
            "val Loss: 0.8007 Acc: 1.0000\n",
            "Epoch 147/499\n",
            "----------\n",
            "train Loss: 0.7992 Acc: 1.0000\n",
            "val Loss: 0.8005 Acc: 1.0000\n",
            "Epoch 148/499\n",
            "----------\n",
            "train Loss: 0.8073 Acc: 1.0000\n",
            "val Loss: 0.8000 Acc: 1.0000\n",
            "Epoch 149/499\n",
            "----------\n",
            "train Loss: 0.7948 Acc: 1.0000\n",
            "val Loss: 0.7998 Acc: 1.0000\n",
            "Epoch 150/499\n",
            "----------\n",
            "train Loss: 0.7915 Acc: 1.0000\n",
            "val Loss: 0.7993 Acc: 1.0000\n",
            "Epoch 151/499\n",
            "----------\n",
            "train Loss: 0.7947 Acc: 1.0000\n",
            "val Loss: 0.7989 Acc: 1.0000\n",
            "Epoch 152/499\n",
            "----------\n",
            "train Loss: 0.8089 Acc: 1.0000\n",
            "val Loss: 0.7981 Acc: 1.0000\n",
            "Epoch 153/499\n",
            "----------\n",
            "train Loss: 0.7941 Acc: 1.0000\n",
            "val Loss: 0.7976 Acc: 1.0000\n",
            "Epoch 154/499\n",
            "----------\n",
            "train Loss: 0.7957 Acc: 1.0000\n",
            "val Loss: 0.7970 Acc: 1.0000\n",
            "Epoch 155/499\n",
            "----------\n",
            "train Loss: 0.7884 Acc: 1.0000\n",
            "val Loss: 0.7969 Acc: 1.0000\n",
            "Epoch 156/499\n",
            "----------\n",
            "train Loss: 0.7929 Acc: 1.0000\n",
            "val Loss: 0.7967 Acc: 1.0000\n",
            "Epoch 157/499\n",
            "----------\n",
            "train Loss: 0.7910 Acc: 1.0000\n",
            "val Loss: 0.7960 Acc: 1.0000\n",
            "Epoch 158/499\n",
            "----------\n",
            "train Loss: 0.7864 Acc: 1.0000\n",
            "val Loss: 0.7957 Acc: 1.0000\n",
            "Epoch 159/499\n",
            "----------\n",
            "train Loss: 0.7882 Acc: 1.0000\n",
            "val Loss: 0.7956 Acc: 1.0000\n",
            "Epoch 160/499\n",
            "----------\n",
            "train Loss: 0.8026 Acc: 1.0000\n",
            "val Loss: 0.7948 Acc: 1.0000\n",
            "Epoch 161/499\n",
            "----------\n",
            "train Loss: 0.7959 Acc: 1.0000\n",
            "val Loss: 0.7945 Acc: 1.0000\n",
            "Epoch 162/499\n",
            "----------\n",
            "train Loss: 0.7986 Acc: 1.0000\n",
            "val Loss: 0.7949 Acc: 1.0000\n",
            "Epoch 163/499\n",
            "----------\n",
            "train Loss: 0.7899 Acc: 1.0000\n",
            "val Loss: 0.7944 Acc: 1.0000\n",
            "Epoch 164/499\n",
            "----------\n",
            "train Loss: 0.7922 Acc: 1.0000\n",
            "val Loss: 0.7943 Acc: 1.0000\n",
            "Epoch 165/499\n",
            "----------\n",
            "train Loss: 0.8018 Acc: 1.0000\n",
            "val Loss: 0.7940 Acc: 1.0000\n",
            "Epoch 166/499\n",
            "----------\n",
            "train Loss: 0.7937 Acc: 1.0000\n",
            "val Loss: 0.7932 Acc: 1.0000\n",
            "Epoch 167/499\n",
            "----------\n",
            "train Loss: 0.7832 Acc: 1.0000\n",
            "val Loss: 0.7930 Acc: 1.0000\n",
            "Epoch 168/499\n",
            "----------\n",
            "train Loss: 0.7841 Acc: 1.0000\n",
            "val Loss: 0.7926 Acc: 1.0000\n",
            "Epoch 169/499\n",
            "----------\n",
            "train Loss: 0.7831 Acc: 1.0000\n",
            "val Loss: 0.7923 Acc: 1.0000\n",
            "Epoch 170/499\n",
            "----------\n",
            "train Loss: 0.7929 Acc: 1.0000\n",
            "val Loss: 0.7922 Acc: 1.0000\n",
            "Epoch 171/499\n",
            "----------\n",
            "train Loss: 0.7952 Acc: 1.0000\n",
            "val Loss: 0.7918 Acc: 1.0000\n",
            "Epoch 172/499\n",
            "----------\n",
            "train Loss: 0.7846 Acc: 1.0000\n",
            "val Loss: 0.7914 Acc: 1.0000\n",
            "Epoch 173/499\n",
            "----------\n",
            "train Loss: 0.7878 Acc: 1.0000\n",
            "val Loss: 0.7906 Acc: 1.0000\n",
            "Epoch 174/499\n",
            "----------\n",
            "train Loss: 0.7788 Acc: 1.0000\n",
            "val Loss: 0.7906 Acc: 1.0000\n",
            "Epoch 175/499\n",
            "----------\n",
            "train Loss: 0.7855 Acc: 1.0000\n",
            "val Loss: 0.7905 Acc: 1.0000\n",
            "Epoch 176/499\n",
            "----------\n",
            "train Loss: 0.7902 Acc: 1.0000\n",
            "val Loss: 0.7903 Acc: 1.0000\n",
            "Epoch 177/499\n",
            "----------\n",
            "train Loss: 0.7810 Acc: 1.0000\n",
            "val Loss: 0.7900 Acc: 1.0000\n",
            "Epoch 178/499\n",
            "----------\n",
            "train Loss: 0.7809 Acc: 1.0000\n",
            "val Loss: 0.7897 Acc: 1.0000\n",
            "Epoch 179/499\n",
            "----------\n",
            "train Loss: 0.7990 Acc: 1.0000\n",
            "val Loss: 0.7897 Acc: 1.0000\n",
            "Epoch 180/499\n",
            "----------\n",
            "train Loss: 0.7810 Acc: 1.0000\n",
            "val Loss: 0.7887 Acc: 1.0000\n",
            "Epoch 181/499\n",
            "----------\n",
            "train Loss: 0.7874 Acc: 1.0000\n",
            "val Loss: 0.7885 Acc: 1.0000\n",
            "Epoch 182/499\n",
            "----------\n",
            "train Loss: 0.7816 Acc: 1.0000\n",
            "val Loss: 0.7891 Acc: 1.0000\n",
            "Epoch 183/499\n",
            "----------\n",
            "train Loss: 0.7891 Acc: 1.0000\n",
            "val Loss: 0.7882 Acc: 1.0000\n",
            "Epoch 184/499\n",
            "----------\n",
            "train Loss: 0.7844 Acc: 1.0000\n",
            "val Loss: 0.7876 Acc: 1.0000\n",
            "Epoch 185/499\n",
            "----------\n",
            "train Loss: 0.7865 Acc: 1.0000\n",
            "val Loss: 0.7876 Acc: 1.0000\n",
            "Epoch 186/499\n",
            "----------\n",
            "train Loss: 0.7793 Acc: 1.0000\n",
            "val Loss: 0.7873 Acc: 1.0000\n",
            "Epoch 187/499\n",
            "----------\n",
            "train Loss: 0.7797 Acc: 1.0000\n",
            "val Loss: 0.7870 Acc: 1.0000\n",
            "Epoch 188/499\n",
            "----------\n",
            "train Loss: 0.7830 Acc: 1.0000\n",
            "val Loss: 0.7864 Acc: 1.0000\n",
            "Epoch 189/499\n",
            "----------\n",
            "train Loss: 0.7812 Acc: 1.0000\n",
            "val Loss: 0.7862 Acc: 1.0000\n",
            "Epoch 190/499\n",
            "----------\n",
            "train Loss: 0.7815 Acc: 1.0000\n",
            "val Loss: 0.7862 Acc: 1.0000\n",
            "Epoch 191/499\n",
            "----------\n",
            "train Loss: 0.7921 Acc: 1.0000\n",
            "val Loss: 0.7855 Acc: 1.0000\n",
            "Epoch 192/499\n",
            "----------\n",
            "train Loss: 0.7761 Acc: 1.0000\n",
            "val Loss: 0.7850 Acc: 1.0000\n",
            "Epoch 193/499\n",
            "----------\n",
            "train Loss: 0.7811 Acc: 1.0000\n",
            "val Loss: 0.7852 Acc: 1.0000\n",
            "Epoch 194/499\n",
            "----------\n",
            "train Loss: 0.7800 Acc: 1.0000\n",
            "val Loss: 0.7846 Acc: 1.0000\n",
            "Epoch 195/499\n",
            "----------\n",
            "train Loss: 0.7868 Acc: 1.0000\n",
            "val Loss: 0.7846 Acc: 1.0000\n",
            "Epoch 196/499\n",
            "----------\n",
            "train Loss: 0.7807 Acc: 1.0000\n",
            "val Loss: 0.7843 Acc: 1.0000\n",
            "Epoch 197/499\n",
            "----------\n",
            "train Loss: 0.7790 Acc: 1.0000\n",
            "val Loss: 0.7839 Acc: 1.0000\n",
            "Epoch 198/499\n",
            "----------\n",
            "train Loss: 0.7778 Acc: 1.0000\n",
            "val Loss: 0.7838 Acc: 1.0000\n",
            "Epoch 199/499\n",
            "----------\n",
            "train Loss: 0.7751 Acc: 1.0000\n",
            "val Loss: 0.7839 Acc: 1.0000\n",
            "Epoch 200/499\n",
            "----------\n",
            "train Loss: 0.7735 Acc: 1.0000\n",
            "val Loss: 0.7837 Acc: 1.0000\n",
            "Epoch 201/499\n",
            "----------\n",
            "train Loss: 0.7914 Acc: 1.0000\n",
            "val Loss: 0.7838 Acc: 1.0000\n",
            "Epoch 202/499\n",
            "----------\n",
            "train Loss: 0.7795 Acc: 1.0000\n",
            "val Loss: 0.7835 Acc: 1.0000\n",
            "Epoch 203/499\n",
            "----------\n",
            "train Loss: 0.7790 Acc: 1.0000\n",
            "val Loss: 0.7835 Acc: 1.0000\n",
            "Epoch 204/499\n",
            "----------\n",
            "train Loss: 0.7730 Acc: 1.0000\n",
            "val Loss: 0.7831 Acc: 1.0000\n",
            "Epoch 205/499\n",
            "----------\n",
            "train Loss: 0.7775 Acc: 1.0000\n",
            "val Loss: 0.7831 Acc: 1.0000\n",
            "Epoch 206/499\n",
            "----------\n",
            "train Loss: 0.7808 Acc: 1.0000\n",
            "val Loss: 0.7828 Acc: 1.0000\n",
            "Epoch 207/499\n",
            "----------\n",
            "train Loss: 0.7779 Acc: 1.0000\n",
            "val Loss: 0.7828 Acc: 1.0000\n",
            "Epoch 208/499\n",
            "----------\n",
            "train Loss: 0.7714 Acc: 1.0000\n",
            "val Loss: 0.7825 Acc: 1.0000\n",
            "Epoch 209/499\n",
            "----------\n",
            "train Loss: 0.7790 Acc: 1.0000\n",
            "val Loss: 0.7822 Acc: 1.0000\n",
            "Epoch 210/499\n",
            "----------\n",
            "train Loss: 0.7767 Acc: 1.0000\n",
            "val Loss: 0.7823 Acc: 1.0000\n",
            "Epoch 211/499\n",
            "----------\n",
            "train Loss: 0.7742 Acc: 1.0000\n",
            "val Loss: 0.7817 Acc: 1.0000\n",
            "Epoch 212/499\n",
            "----------\n",
            "train Loss: 0.7834 Acc: 1.0000\n",
            "val Loss: 0.7814 Acc: 1.0000\n",
            "Epoch 213/499\n",
            "----------\n",
            "train Loss: 0.7735 Acc: 1.0000\n",
            "val Loss: 0.7809 Acc: 1.0000\n",
            "Epoch 214/499\n",
            "----------\n",
            "train Loss: 0.7764 Acc: 1.0000\n",
            "val Loss: 0.7810 Acc: 1.0000\n",
            "Epoch 215/499\n",
            "----------\n",
            "train Loss: 0.7752 Acc: 1.0000\n",
            "val Loss: 0.7809 Acc: 1.0000\n",
            "Epoch 216/499\n",
            "----------\n",
            "train Loss: 0.7801 Acc: 1.0000\n",
            "val Loss: 0.7815 Acc: 1.0000\n",
            "Epoch 217/499\n",
            "----------\n",
            "train Loss: 0.7744 Acc: 1.0000\n",
            "val Loss: 0.7808 Acc: 1.0000\n",
            "Epoch 218/499\n",
            "----------\n",
            "train Loss: 0.7819 Acc: 1.0000\n",
            "val Loss: 0.7797 Acc: 1.0000\n",
            "Epoch 219/499\n",
            "----------\n",
            "train Loss: 0.7722 Acc: 1.0000\n",
            "val Loss: 0.7800 Acc: 1.0000\n",
            "Epoch 220/499\n",
            "----------\n",
            "train Loss: 0.7755 Acc: 1.0000\n",
            "val Loss: 0.7804 Acc: 1.0000\n",
            "Epoch 221/499\n",
            "----------\n",
            "train Loss: 0.7736 Acc: 1.0000\n",
            "val Loss: 0.7796 Acc: 1.0000\n",
            "Epoch 222/499\n",
            "----------\n",
            "train Loss: 0.7729 Acc: 1.0000\n",
            "val Loss: 0.7793 Acc: 1.0000\n",
            "Epoch 223/499\n",
            "----------\n",
            "train Loss: 0.7718 Acc: 1.0000\n",
            "val Loss: 0.7793 Acc: 1.0000\n",
            "Epoch 224/499\n",
            "----------\n",
            "train Loss: 0.7773 Acc: 1.0000\n",
            "val Loss: 0.7786 Acc: 1.0000\n",
            "Epoch 225/499\n",
            "----------\n",
            "train Loss: 0.7705 Acc: 1.0000\n",
            "val Loss: 0.7785 Acc: 1.0000\n",
            "Epoch 226/499\n",
            "----------\n",
            "train Loss: 0.7717 Acc: 1.0000\n",
            "val Loss: 0.7787 Acc: 1.0000\n",
            "Epoch 227/499\n",
            "----------\n",
            "train Loss: 0.7756 Acc: 1.0000\n",
            "val Loss: 0.7789 Acc: 1.0000\n",
            "Epoch 228/499\n",
            "----------\n",
            "train Loss: 0.7718 Acc: 1.0000\n",
            "val Loss: 0.7790 Acc: 1.0000\n",
            "Epoch 229/499\n",
            "----------\n",
            "train Loss: 0.7757 Acc: 1.0000\n",
            "val Loss: 0.7783 Acc: 1.0000\n",
            "Epoch 230/499\n",
            "----------\n",
            "train Loss: 0.7741 Acc: 1.0000\n",
            "val Loss: 0.7783 Acc: 1.0000\n",
            "Epoch 231/499\n",
            "----------\n",
            "train Loss: 0.7704 Acc: 1.0000\n",
            "val Loss: 0.7787 Acc: 1.0000\n",
            "Epoch 232/499\n",
            "----------\n",
            "train Loss: 0.7736 Acc: 1.0000\n",
            "val Loss: 0.7783 Acc: 1.0000\n",
            "Epoch 233/499\n",
            "----------\n",
            "train Loss: 0.7747 Acc: 1.0000\n",
            "val Loss: 0.7777 Acc: 1.0000\n",
            "Epoch 234/499\n",
            "----------\n",
            "train Loss: 0.7697 Acc: 1.0000\n",
            "val Loss: 0.7776 Acc: 1.0000\n",
            "Epoch 235/499\n",
            "----------\n",
            "train Loss: 0.7712 Acc: 1.0000\n",
            "val Loss: 0.7773 Acc: 1.0000\n",
            "Epoch 236/499\n",
            "----------\n",
            "train Loss: 0.7806 Acc: 1.0000\n",
            "val Loss: 0.7772 Acc: 1.0000\n",
            "Epoch 237/499\n",
            "----------\n",
            "train Loss: 0.7754 Acc: 1.0000\n",
            "val Loss: 0.7773 Acc: 1.0000\n",
            "Epoch 238/499\n",
            "----------\n",
            "train Loss: 0.7695 Acc: 1.0000\n",
            "val Loss: 0.7770 Acc: 1.0000\n",
            "Epoch 239/499\n",
            "----------\n",
            "train Loss: 0.7723 Acc: 1.0000\n",
            "val Loss: 0.7767 Acc: 1.0000\n",
            "Epoch 240/499\n",
            "----------\n",
            "train Loss: 0.7761 Acc: 1.0000\n",
            "val Loss: 0.7766 Acc: 1.0000\n",
            "Epoch 241/499\n",
            "----------\n",
            "train Loss: 0.7714 Acc: 1.0000\n",
            "val Loss: 0.7764 Acc: 1.0000\n",
            "Epoch 242/499\n",
            "----------\n",
            "train Loss: 0.7673 Acc: 1.0000\n",
            "val Loss: 0.7764 Acc: 1.0000\n",
            "Epoch 243/499\n",
            "----------\n",
            "train Loss: 0.7706 Acc: 1.0000\n",
            "val Loss: 0.7763 Acc: 1.0000\n",
            "Epoch 244/499\n",
            "----------\n",
            "train Loss: 0.7670 Acc: 1.0000\n",
            "val Loss: 0.7760 Acc: 1.0000\n",
            "Epoch 245/499\n",
            "----------\n",
            "train Loss: 0.7724 Acc: 1.0000\n",
            "val Loss: 0.7762 Acc: 1.0000\n",
            "Epoch 246/499\n",
            "----------\n",
            "train Loss: 0.7810 Acc: 1.0000\n",
            "val Loss: 0.7760 Acc: 1.0000\n",
            "Epoch 247/499\n",
            "----------\n",
            "train Loss: 0.7704 Acc: 1.0000\n",
            "val Loss: 0.7759 Acc: 1.0000\n",
            "Epoch 248/499\n",
            "----------\n",
            "train Loss: 0.7732 Acc: 1.0000\n",
            "val Loss: 0.7755 Acc: 1.0000\n",
            "Epoch 249/499\n",
            "----------\n",
            "train Loss: 0.7690 Acc: 1.0000\n",
            "val Loss: 0.7753 Acc: 1.0000\n",
            "Epoch 250/499\n",
            "----------\n",
            "train Loss: 0.7721 Acc: 1.0000\n",
            "val Loss: 0.7753 Acc: 1.0000\n",
            "Epoch 251/499\n",
            "----------\n",
            "train Loss: 0.7725 Acc: 1.0000\n",
            "val Loss: 0.7756 Acc: 1.0000\n",
            "Epoch 252/499\n",
            "----------\n",
            "train Loss: 0.7759 Acc: 1.0000\n",
            "val Loss: 0.7754 Acc: 1.0000\n",
            "Epoch 253/499\n",
            "----------\n",
            "train Loss: 0.7733 Acc: 1.0000\n",
            "val Loss: 0.7752 Acc: 1.0000\n",
            "Epoch 254/499\n",
            "----------\n",
            "train Loss: 0.7664 Acc: 1.0000\n",
            "val Loss: 0.7750 Acc: 1.0000\n",
            "Epoch 255/499\n",
            "----------\n",
            "train Loss: 0.7716 Acc: 1.0000\n",
            "val Loss: 0.7746 Acc: 1.0000\n",
            "Epoch 256/499\n",
            "----------\n",
            "train Loss: 0.7666 Acc: 1.0000\n",
            "val Loss: 0.7747 Acc: 1.0000\n",
            "Epoch 257/499\n",
            "----------\n",
            "train Loss: 0.7709 Acc: 1.0000\n",
            "val Loss: 0.7744 Acc: 1.0000\n",
            "Epoch 258/499\n",
            "----------\n",
            "train Loss: 0.7694 Acc: 1.0000\n",
            "val Loss: 0.7741 Acc: 1.0000\n",
            "Epoch 259/499\n",
            "----------\n",
            "train Loss: 0.7738 Acc: 1.0000\n",
            "val Loss: 0.7747 Acc: 1.0000\n",
            "Epoch 260/499\n",
            "----------\n",
            "train Loss: 0.7668 Acc: 1.0000\n",
            "val Loss: 0.7740 Acc: 1.0000\n",
            "Epoch 261/499\n",
            "----------\n",
            "train Loss: 0.7695 Acc: 1.0000\n",
            "val Loss: 0.7740 Acc: 1.0000\n",
            "Epoch 262/499\n",
            "----------\n",
            "train Loss: 0.7657 Acc: 1.0000\n",
            "val Loss: 0.7740 Acc: 1.0000\n",
            "Epoch 263/499\n",
            "----------\n",
            "train Loss: 0.7695 Acc: 1.0000\n",
            "val Loss: 0.7738 Acc: 1.0000\n",
            "Epoch 264/499\n",
            "----------\n",
            "train Loss: 0.7662 Acc: 1.0000\n",
            "val Loss: 0.7736 Acc: 1.0000\n",
            "Epoch 265/499\n",
            "----------\n",
            "train Loss: 0.7660 Acc: 1.0000\n",
            "val Loss: 0.7734 Acc: 1.0000\n",
            "Epoch 266/499\n",
            "----------\n",
            "train Loss: 0.7702 Acc: 1.0000\n",
            "val Loss: 0.7732 Acc: 1.0000\n",
            "Epoch 267/499\n",
            "----------\n",
            "train Loss: 0.7665 Acc: 1.0000\n",
            "val Loss: 0.7731 Acc: 1.0000\n",
            "Epoch 268/499\n",
            "----------\n",
            "train Loss: 0.7685 Acc: 1.0000\n",
            "val Loss: 0.7728 Acc: 1.0000\n",
            "Epoch 269/499\n",
            "----------\n",
            "train Loss: 0.7696 Acc: 1.0000\n",
            "val Loss: 0.7730 Acc: 1.0000\n",
            "Epoch 270/499\n",
            "----------\n",
            "train Loss: 0.7657 Acc: 1.0000\n",
            "val Loss: 0.7730 Acc: 1.0000\n",
            "Epoch 271/499\n",
            "----------\n",
            "train Loss: 0.7678 Acc: 1.0000\n",
            "val Loss: 0.7728 Acc: 1.0000\n",
            "Epoch 272/499\n",
            "----------\n",
            "train Loss: 0.7774 Acc: 1.0000\n",
            "val Loss: 0.7727 Acc: 1.0000\n",
            "Epoch 273/499\n",
            "----------\n",
            "train Loss: 0.7689 Acc: 1.0000\n",
            "val Loss: 0.7723 Acc: 1.0000\n",
            "Epoch 274/499\n",
            "----------\n",
            "train Loss: 0.7730 Acc: 1.0000\n",
            "val Loss: 0.7722 Acc: 1.0000\n",
            "Epoch 275/499\n",
            "----------\n",
            "train Loss: 0.7646 Acc: 1.0000\n",
            "val Loss: 0.7724 Acc: 1.0000\n",
            "Epoch 276/499\n",
            "----------\n",
            "train Loss: 0.7693 Acc: 1.0000\n",
            "val Loss: 0.7724 Acc: 1.0000\n",
            "Epoch 277/499\n",
            "----------\n",
            "train Loss: 0.7647 Acc: 1.0000\n",
            "val Loss: 0.7722 Acc: 1.0000\n",
            "Epoch 278/499\n",
            "----------\n",
            "train Loss: 0.7705 Acc: 1.0000\n",
            "val Loss: 0.7723 Acc: 1.0000\n",
            "Epoch 279/499\n",
            "----------\n",
            "train Loss: 0.7697 Acc: 1.0000\n",
            "val Loss: 0.7723 Acc: 1.0000\n",
            "Epoch 280/499\n",
            "----------\n",
            "train Loss: 0.7748 Acc: 1.0000\n",
            "val Loss: 0.7720 Acc: 1.0000\n",
            "Epoch 281/499\n",
            "----------\n",
            "train Loss: 0.7720 Acc: 1.0000\n",
            "val Loss: 0.7720 Acc: 1.0000\n",
            "Epoch 282/499\n",
            "----------\n",
            "train Loss: 0.7718 Acc: 1.0000\n",
            "val Loss: 0.7719 Acc: 1.0000\n",
            "Epoch 283/499\n",
            "----------\n",
            "train Loss: 0.7665 Acc: 1.0000\n",
            "val Loss: 0.7721 Acc: 1.0000\n",
            "Epoch 284/499\n",
            "----------\n",
            "train Loss: 0.7649 Acc: 1.0000\n",
            "val Loss: 0.7720 Acc: 1.0000\n",
            "Epoch 285/499\n",
            "----------\n",
            "train Loss: 0.7647 Acc: 1.0000\n",
            "val Loss: 0.7722 Acc: 1.0000\n",
            "Epoch 286/499\n",
            "----------\n",
            "train Loss: 0.7653 Acc: 1.0000\n",
            "val Loss: 0.7715 Acc: 1.0000\n",
            "Epoch 287/499\n",
            "----------\n",
            "train Loss: 0.7696 Acc: 1.0000\n",
            "val Loss: 0.7713 Acc: 1.0000\n",
            "Epoch 288/499\n",
            "----------\n",
            "train Loss: 0.7684 Acc: 1.0000\n",
            "val Loss: 0.7708 Acc: 1.0000\n",
            "Epoch 289/499\n",
            "----------\n",
            "train Loss: 0.7662 Acc: 1.0000\n",
            "val Loss: 0.7709 Acc: 1.0000\n",
            "Epoch 290/499\n",
            "----------\n",
            "train Loss: 0.7666 Acc: 1.0000\n",
            "val Loss: 0.7710 Acc: 1.0000\n",
            "Epoch 291/499\n",
            "----------\n",
            "train Loss: 0.7668 Acc: 1.0000\n",
            "val Loss: 0.7704 Acc: 1.0000\n",
            "Epoch 292/499\n",
            "----------\n",
            "train Loss: 0.7662 Acc: 1.0000\n",
            "val Loss: 0.7704 Acc: 1.0000\n",
            "Epoch 293/499\n",
            "----------\n",
            "train Loss: 0.7641 Acc: 1.0000\n",
            "val Loss: 0.7705 Acc: 1.0000\n",
            "Epoch 294/499\n",
            "----------\n",
            "train Loss: 0.7657 Acc: 1.0000\n",
            "val Loss: 0.7704 Acc: 1.0000\n",
            "Epoch 295/499\n",
            "----------\n",
            "train Loss: 0.7722 Acc: 1.0000\n",
            "val Loss: 0.7703 Acc: 1.0000\n",
            "Epoch 296/499\n",
            "----------\n",
            "train Loss: 0.7678 Acc: 1.0000\n",
            "val Loss: 0.7700 Acc: 1.0000\n",
            "Epoch 297/499\n",
            "----------\n",
            "train Loss: 0.7665 Acc: 1.0000\n",
            "val Loss: 0.7700 Acc: 1.0000\n",
            "Epoch 298/499\n",
            "----------\n",
            "train Loss: 0.7654 Acc: 1.0000\n",
            "val Loss: 0.7700 Acc: 1.0000\n",
            "Epoch 299/499\n",
            "----------\n",
            "train Loss: 0.7647 Acc: 1.0000\n",
            "val Loss: 0.7699 Acc: 1.0000\n",
            "Epoch 300/499\n",
            "----------\n",
            "train Loss: 0.7694 Acc: 1.0000\n",
            "val Loss: 0.7698 Acc: 1.0000\n",
            "Epoch 301/499\n",
            "----------\n",
            "train Loss: 0.7648 Acc: 1.0000\n",
            "val Loss: 0.7696 Acc: 1.0000\n",
            "Epoch 302/499\n",
            "----------\n",
            "train Loss: 0.7649 Acc: 1.0000\n",
            "val Loss: 0.7694 Acc: 1.0000\n",
            "Epoch 303/499\n",
            "----------\n",
            "train Loss: 0.7652 Acc: 1.0000\n",
            "val Loss: 0.7694 Acc: 1.0000\n",
            "Epoch 304/499\n",
            "----------\n",
            "train Loss: 0.7682 Acc: 1.0000\n",
            "val Loss: 0.7692 Acc: 1.0000\n",
            "Epoch 305/499\n",
            "----------\n",
            "train Loss: 0.7643 Acc: 1.0000\n",
            "val Loss: 0.7692 Acc: 1.0000\n",
            "Epoch 306/499\n",
            "----------\n",
            "train Loss: 0.7634 Acc: 1.0000\n",
            "val Loss: 0.7691 Acc: 1.0000\n",
            "Epoch 307/499\n",
            "----------\n",
            "train Loss: 0.7618 Acc: 1.0000\n",
            "val Loss: 0.7692 Acc: 1.0000\n",
            "Epoch 308/499\n",
            "----------\n",
            "train Loss: 0.7664 Acc: 1.0000\n",
            "val Loss: 0.7688 Acc: 1.0000\n",
            "Epoch 309/499\n",
            "----------\n",
            "train Loss: 0.7665 Acc: 1.0000\n",
            "val Loss: 0.7690 Acc: 1.0000\n",
            "Epoch 310/499\n",
            "----------\n",
            "train Loss: 0.7618 Acc: 1.0000\n",
            "val Loss: 0.7689 Acc: 1.0000\n",
            "Epoch 311/499\n",
            "----------\n",
            "train Loss: 0.7619 Acc: 1.0000\n",
            "val Loss: 0.7689 Acc: 1.0000\n",
            "Epoch 312/499\n",
            "----------\n",
            "train Loss: 0.7666 Acc: 1.0000\n",
            "val Loss: 0.7688 Acc: 1.0000\n",
            "Epoch 313/499\n",
            "----------\n",
            "train Loss: 0.7620 Acc: 1.0000\n",
            "val Loss: 0.7685 Acc: 1.0000\n",
            "Epoch 314/499\n",
            "----------\n",
            "train Loss: 0.7636 Acc: 1.0000\n",
            "val Loss: 0.7687 Acc: 1.0000\n",
            "Epoch 315/499\n",
            "----------\n",
            "train Loss: 0.7606 Acc: 1.0000\n",
            "val Loss: 0.7689 Acc: 1.0000\n",
            "Epoch 316/499\n",
            "----------\n",
            "train Loss: 0.7626 Acc: 1.0000\n",
            "val Loss: 0.7691 Acc: 1.0000\n",
            "Epoch 317/499\n",
            "----------\n",
            "train Loss: 0.7640 Acc: 1.0000\n",
            "val Loss: 0.7693 Acc: 1.0000\n",
            "Epoch 318/499\n",
            "----------\n",
            "train Loss: 0.7698 Acc: 1.0000\n",
            "val Loss: 0.7684 Acc: 1.0000\n",
            "Epoch 319/499\n",
            "----------\n",
            "train Loss: 0.7659 Acc: 1.0000\n",
            "val Loss: 0.7683 Acc: 1.0000\n",
            "Epoch 320/499\n",
            "----------\n",
            "train Loss: 0.7664 Acc: 1.0000\n",
            "val Loss: 0.7685 Acc: 1.0000\n",
            "Epoch 321/499\n",
            "----------\n",
            "train Loss: 0.7631 Acc: 1.0000\n",
            "val Loss: 0.7688 Acc: 1.0000\n",
            "Epoch 322/499\n",
            "----------\n",
            "train Loss: 0.7625 Acc: 1.0000\n",
            "val Loss: 0.7690 Acc: 1.0000\n",
            "Epoch 323/499\n",
            "----------\n",
            "train Loss: 0.7641 Acc: 1.0000\n",
            "val Loss: 0.7682 Acc: 1.0000\n",
            "Epoch 324/499\n",
            "----------\n",
            "train Loss: 0.7614 Acc: 1.0000\n",
            "val Loss: 0.7679 Acc: 1.0000\n",
            "Epoch 325/499\n",
            "----------\n",
            "train Loss: 0.7654 Acc: 1.0000\n",
            "val Loss: 0.7679 Acc: 1.0000\n",
            "Epoch 326/499\n",
            "----------\n",
            "train Loss: 0.7614 Acc: 1.0000\n",
            "val Loss: 0.7680 Acc: 1.0000\n",
            "Epoch 327/499\n",
            "----------\n",
            "train Loss: 0.7677 Acc: 1.0000\n",
            "val Loss: 0.7682 Acc: 1.0000\n",
            "Epoch 328/499\n",
            "----------\n",
            "train Loss: 0.7627 Acc: 1.0000\n",
            "val Loss: 0.7680 Acc: 1.0000\n",
            "Epoch 329/499\n",
            "----------\n",
            "train Loss: 0.7600 Acc: 1.0000\n",
            "val Loss: 0.7681 Acc: 1.0000\n",
            "Epoch 330/499\n",
            "----------\n",
            "train Loss: 0.7653 Acc: 1.0000\n",
            "val Loss: 0.7680 Acc: 1.0000\n",
            "Epoch 331/499\n",
            "----------\n",
            "train Loss: 0.7705 Acc: 1.0000\n",
            "val Loss: 0.7679 Acc: 1.0000\n",
            "Epoch 332/499\n",
            "----------\n",
            "train Loss: 0.7648 Acc: 1.0000\n",
            "val Loss: 0.7676 Acc: 1.0000\n",
            "Epoch 333/499\n",
            "----------\n",
            "train Loss: 0.7637 Acc: 1.0000\n",
            "val Loss: 0.7675 Acc: 1.0000\n",
            "Epoch 334/499\n",
            "----------\n",
            "train Loss: 0.7605 Acc: 1.0000\n",
            "val Loss: 0.7672 Acc: 1.0000\n",
            "Epoch 335/499\n",
            "----------\n",
            "train Loss: 0.7643 Acc: 1.0000\n",
            "val Loss: 0.7672 Acc: 1.0000\n",
            "Epoch 336/499\n",
            "----------\n",
            "train Loss: 0.7605 Acc: 1.0000\n",
            "val Loss: 0.7672 Acc: 1.0000\n",
            "Epoch 337/499\n",
            "----------\n",
            "train Loss: 0.7626 Acc: 1.0000\n",
            "val Loss: 0.7673 Acc: 1.0000\n",
            "Epoch 338/499\n",
            "----------\n",
            "train Loss: 0.7633 Acc: 1.0000\n",
            "val Loss: 0.7670 Acc: 1.0000\n",
            "Epoch 339/499\n",
            "----------\n",
            "train Loss: 0.7712 Acc: 1.0000\n",
            "val Loss: 0.7670 Acc: 1.0000\n",
            "Epoch 340/499\n",
            "----------\n",
            "train Loss: 0.7599 Acc: 1.0000\n",
            "val Loss: 0.7668 Acc: 1.0000\n",
            "Epoch 341/499\n",
            "----------\n",
            "train Loss: 0.7662 Acc: 1.0000\n",
            "val Loss: 0.7677 Acc: 1.0000\n",
            "Epoch 342/499\n",
            "----------\n",
            "train Loss: 0.7619 Acc: 1.0000\n",
            "val Loss: 0.7676 Acc: 1.0000\n",
            "Epoch 343/499\n",
            "----------\n",
            "train Loss: 0.7600 Acc: 1.0000\n",
            "val Loss: 0.7671 Acc: 1.0000\n",
            "Epoch 344/499\n",
            "----------\n",
            "train Loss: 0.7588 Acc: 1.0000\n",
            "val Loss: 0.7668 Acc: 1.0000\n",
            "Epoch 345/499\n",
            "----------\n",
            "train Loss: 0.7727 Acc: 1.0000\n",
            "val Loss: 0.7665 Acc: 1.0000\n",
            "Epoch 346/499\n",
            "----------\n",
            "train Loss: 0.7615 Acc: 1.0000\n",
            "val Loss: 0.7666 Acc: 1.0000\n",
            "Epoch 347/499\n",
            "----------\n",
            "train Loss: 0.7594 Acc: 1.0000\n",
            "val Loss: 0.7668 Acc: 1.0000\n",
            "Epoch 348/499\n",
            "----------\n",
            "train Loss: 0.7649 Acc: 1.0000\n",
            "val Loss: 0.7663 Acc: 1.0000\n",
            "Epoch 349/499\n",
            "----------\n",
            "train Loss: 0.7611 Acc: 1.0000\n",
            "val Loss: 0.7666 Acc: 1.0000\n",
            "Epoch 350/499\n",
            "----------\n",
            "train Loss: 0.7620 Acc: 1.0000\n",
            "val Loss: 0.7666 Acc: 1.0000\n",
            "Epoch 351/499\n",
            "----------\n",
            "train Loss: 0.7602 Acc: 1.0000\n",
            "val Loss: 0.7668 Acc: 1.0000\n",
            "Epoch 352/499\n",
            "----------\n",
            "train Loss: 0.7612 Acc: 1.0000\n",
            "val Loss: 0.7666 Acc: 1.0000\n",
            "Epoch 353/499\n",
            "----------\n",
            "train Loss: 0.7649 Acc: 1.0000\n",
            "val Loss: 0.7662 Acc: 1.0000\n",
            "Epoch 354/499\n",
            "----------\n",
            "train Loss: 0.7606 Acc: 1.0000\n",
            "val Loss: 0.7663 Acc: 1.0000\n",
            "Epoch 355/499\n",
            "----------\n",
            "train Loss: 0.7593 Acc: 1.0000\n",
            "val Loss: 0.7658 Acc: 1.0000\n",
            "Epoch 356/499\n",
            "----------\n",
            "train Loss: 0.7612 Acc: 1.0000\n",
            "val Loss: 0.7659 Acc: 1.0000\n",
            "Epoch 357/499\n",
            "----------\n",
            "train Loss: 0.7615 Acc: 1.0000\n",
            "val Loss: 0.7657 Acc: 1.0000\n",
            "Epoch 358/499\n",
            "----------\n",
            "train Loss: 0.7622 Acc: 1.0000\n",
            "val Loss: 0.7655 Acc: 1.0000\n",
            "Epoch 359/499\n",
            "----------\n",
            "train Loss: 0.7619 Acc: 1.0000\n",
            "val Loss: 0.7659 Acc: 1.0000\n",
            "Epoch 360/499\n",
            "----------\n",
            "train Loss: 0.7601 Acc: 1.0000\n",
            "val Loss: 0.7657 Acc: 1.0000\n",
            "Epoch 361/499\n",
            "----------\n",
            "train Loss: 0.7617 Acc: 1.0000\n",
            "val Loss: 0.7654 Acc: 1.0000\n",
            "Epoch 362/499\n",
            "----------\n",
            "train Loss: 0.7579 Acc: 1.0000\n",
            "val Loss: 0.7652 Acc: 1.0000\n",
            "Epoch 363/499\n",
            "----------\n",
            "train Loss: 0.7616 Acc: 1.0000\n",
            "val Loss: 0.7653 Acc: 1.0000\n",
            "Epoch 364/499\n",
            "----------\n",
            "train Loss: 0.7636 Acc: 1.0000\n",
            "val Loss: 0.7650 Acc: 1.0000\n",
            "Epoch 365/499\n",
            "----------\n",
            "train Loss: 0.7577 Acc: 1.0000\n",
            "val Loss: 0.7651 Acc: 1.0000\n",
            "Epoch 366/499\n",
            "----------\n",
            "train Loss: 0.7648 Acc: 1.0000\n",
            "val Loss: 0.7650 Acc: 1.0000\n",
            "Epoch 367/499\n",
            "----------\n",
            "train Loss: 0.7631 Acc: 1.0000\n",
            "val Loss: 0.7649 Acc: 1.0000\n",
            "Epoch 368/499\n",
            "----------\n",
            "train Loss: 0.7583 Acc: 1.0000\n",
            "val Loss: 0.7649 Acc: 1.0000\n",
            "Epoch 369/499\n",
            "----------\n",
            "train Loss: 0.7585 Acc: 1.0000\n",
            "val Loss: 0.7649 Acc: 1.0000\n",
            "Epoch 370/499\n",
            "----------\n",
            "train Loss: 0.7605 Acc: 1.0000\n",
            "val Loss: 0.7649 Acc: 1.0000\n",
            "Epoch 371/499\n",
            "----------\n",
            "train Loss: 0.7594 Acc: 1.0000\n",
            "val Loss: 0.7650 Acc: 1.0000\n",
            "Epoch 372/499\n",
            "----------\n",
            "train Loss: 0.7645 Acc: 1.0000\n",
            "val Loss: 0.7652 Acc: 1.0000\n",
            "Epoch 373/499\n",
            "----------\n",
            "train Loss: 0.7657 Acc: 1.0000\n",
            "val Loss: 0.7650 Acc: 1.0000\n",
            "Epoch 374/499\n",
            "----------\n",
            "train Loss: 0.7589 Acc: 1.0000\n",
            "val Loss: 0.7653 Acc: 1.0000\n",
            "Epoch 375/499\n",
            "----------\n",
            "train Loss: 0.7603 Acc: 1.0000\n",
            "val Loss: 0.7652 Acc: 1.0000\n",
            "Epoch 376/499\n",
            "----------\n",
            "train Loss: 0.7654 Acc: 1.0000\n",
            "val Loss: 0.7655 Acc: 1.0000\n",
            "Epoch 377/499\n",
            "----------\n",
            "train Loss: 0.7592 Acc: 1.0000\n",
            "val Loss: 0.7650 Acc: 1.0000\n",
            "Epoch 378/499\n",
            "----------\n",
            "train Loss: 0.7637 Acc: 1.0000\n",
            "val Loss: 0.7650 Acc: 1.0000\n",
            "Epoch 379/499\n",
            "----------\n",
            "train Loss: 0.7587 Acc: 1.0000\n",
            "val Loss: 0.7649 Acc: 1.0000\n",
            "Epoch 380/499\n",
            "----------\n",
            "train Loss: 0.7614 Acc: 1.0000\n",
            "val Loss: 0.7645 Acc: 1.0000\n",
            "Epoch 381/499\n",
            "----------\n",
            "train Loss: 0.7665 Acc: 1.0000\n",
            "val Loss: 0.7646 Acc: 1.0000\n",
            "Epoch 382/499\n",
            "----------\n",
            "train Loss: 0.7592 Acc: 1.0000\n",
            "val Loss: 0.7647 Acc: 1.0000\n",
            "Epoch 383/499\n",
            "----------\n",
            "train Loss: 0.7610 Acc: 1.0000\n",
            "val Loss: 0.7644 Acc: 1.0000\n",
            "Epoch 384/499\n",
            "----------\n",
            "train Loss: 0.7615 Acc: 1.0000\n",
            "val Loss: 0.7644 Acc: 1.0000\n",
            "Epoch 385/499\n",
            "----------\n",
            "train Loss: 0.7611 Acc: 1.0000\n",
            "val Loss: 0.7644 Acc: 1.0000\n",
            "Epoch 386/499\n",
            "----------\n",
            "train Loss: 0.7596 Acc: 1.0000\n",
            "val Loss: 0.7642 Acc: 1.0000\n",
            "Epoch 387/499\n",
            "----------\n",
            "train Loss: 0.7633 Acc: 1.0000\n",
            "val Loss: 0.7641 Acc: 1.0000\n",
            "Epoch 388/499\n",
            "----------\n",
            "train Loss: 0.7586 Acc: 1.0000\n",
            "val Loss: 0.7643 Acc: 1.0000\n",
            "Epoch 389/499\n",
            "----------\n",
            "train Loss: 0.7614 Acc: 1.0000\n",
            "val Loss: 0.7640 Acc: 1.0000\n",
            "Epoch 390/499\n",
            "----------\n",
            "train Loss: 0.7749 Acc: 1.0000\n",
            "val Loss: 0.7642 Acc: 1.0000\n",
            "Epoch 391/499\n",
            "----------\n",
            "train Loss: 0.7611 Acc: 1.0000\n",
            "val Loss: 0.7640 Acc: 1.0000\n",
            "Epoch 392/499\n",
            "----------\n",
            "train Loss: 0.7599 Acc: 1.0000\n",
            "val Loss: 0.7641 Acc: 1.0000\n",
            "Epoch 393/499\n",
            "----------\n",
            "train Loss: 0.7572 Acc: 1.0000\n",
            "val Loss: 0.7642 Acc: 1.0000\n",
            "Epoch 394/499\n",
            "----------\n",
            "train Loss: 0.7593 Acc: 1.0000\n",
            "val Loss: 0.7640 Acc: 1.0000\n",
            "Epoch 395/499\n",
            "----------\n",
            "train Loss: 0.7586 Acc: 1.0000\n",
            "val Loss: 0.7640 Acc: 1.0000\n",
            "Epoch 396/499\n",
            "----------\n",
            "train Loss: 0.7618 Acc: 1.0000\n",
            "val Loss: 0.7639 Acc: 1.0000\n",
            "Epoch 397/499\n",
            "----------\n",
            "train Loss: 0.7590 Acc: 1.0000\n",
            "val Loss: 0.7636 Acc: 1.0000\n",
            "Epoch 398/499\n",
            "----------\n",
            "train Loss: 0.7587 Acc: 1.0000\n",
            "val Loss: 0.7639 Acc: 1.0000\n",
            "Epoch 399/499\n",
            "----------\n",
            "train Loss: 0.7557 Acc: 1.0000\n",
            "val Loss: 0.7640 Acc: 1.0000\n",
            "Epoch 400/499\n",
            "----------\n",
            "train Loss: 0.7570 Acc: 1.0000\n",
            "val Loss: 0.7638 Acc: 1.0000\n",
            "Epoch 401/499\n",
            "----------\n",
            "train Loss: 0.7607 Acc: 1.0000\n",
            "val Loss: 0.7641 Acc: 1.0000\n",
            "Epoch 402/499\n",
            "----------\n",
            "train Loss: 0.7637 Acc: 1.0000\n",
            "val Loss: 0.7637 Acc: 1.0000\n",
            "Epoch 403/499\n",
            "----------\n",
            "train Loss: 0.7573 Acc: 1.0000\n",
            "val Loss: 0.7634 Acc: 1.0000\n",
            "Epoch 404/499\n",
            "----------\n",
            "train Loss: 0.7582 Acc: 1.0000\n",
            "val Loss: 0.7633 Acc: 1.0000\n",
            "Epoch 405/499\n",
            "----------\n",
            "train Loss: 0.7634 Acc: 1.0000\n",
            "val Loss: 0.7638 Acc: 1.0000\n",
            "Epoch 406/499\n",
            "----------\n",
            "train Loss: 0.7648 Acc: 1.0000\n",
            "val Loss: 0.7634 Acc: 1.0000\n",
            "Epoch 407/499\n",
            "----------\n",
            "train Loss: 0.7592 Acc: 1.0000\n",
            "val Loss: 0.7633 Acc: 1.0000\n",
            "Epoch 408/499\n",
            "----------\n",
            "train Loss: 0.7611 Acc: 1.0000\n",
            "val Loss: 0.7632 Acc: 1.0000\n",
            "Epoch 409/499\n",
            "----------\n",
            "train Loss: 0.7576 Acc: 1.0000\n",
            "val Loss: 0.7632 Acc: 1.0000\n",
            "Epoch 410/499\n",
            "----------\n",
            "train Loss: 0.7670 Acc: 1.0000\n",
            "val Loss: 0.7635 Acc: 1.0000\n",
            "Epoch 411/499\n",
            "----------\n",
            "train Loss: 0.7617 Acc: 1.0000\n",
            "val Loss: 0.7632 Acc: 1.0000\n",
            "Epoch 412/499\n",
            "----------\n",
            "train Loss: 0.7573 Acc: 1.0000\n",
            "val Loss: 0.7631 Acc: 1.0000\n",
            "Epoch 413/499\n",
            "----------\n",
            "train Loss: 0.7581 Acc: 1.0000\n",
            "val Loss: 0.7630 Acc: 1.0000\n",
            "Epoch 414/499\n",
            "----------\n",
            "train Loss: 0.7583 Acc: 1.0000\n",
            "val Loss: 0.7629 Acc: 1.0000\n",
            "Epoch 415/499\n",
            "----------\n",
            "train Loss: 0.7607 Acc: 1.0000\n",
            "val Loss: 0.7628 Acc: 1.0000\n",
            "Epoch 416/499\n",
            "----------\n",
            "train Loss: 0.7580 Acc: 1.0000\n",
            "val Loss: 0.7628 Acc: 1.0000\n",
            "Epoch 417/499\n",
            "----------\n",
            "train Loss: 0.7597 Acc: 1.0000\n",
            "val Loss: 0.7627 Acc: 1.0000\n",
            "Epoch 418/499\n",
            "----------\n",
            "train Loss: 0.7573 Acc: 1.0000\n",
            "val Loss: 0.7624 Acc: 1.0000\n",
            "Epoch 419/499\n",
            "----------\n",
            "train Loss: 0.7562 Acc: 1.0000\n",
            "val Loss: 0.7626 Acc: 1.0000\n",
            "Epoch 420/499\n",
            "----------\n",
            "train Loss: 0.7592 Acc: 1.0000\n",
            "val Loss: 0.7626 Acc: 1.0000\n",
            "Epoch 421/499\n",
            "----------\n",
            "train Loss: 0.7625 Acc: 1.0000\n",
            "val Loss: 0.7628 Acc: 1.0000\n",
            "Epoch 422/499\n",
            "----------\n",
            "train Loss: 0.7744 Acc: 1.0000\n",
            "val Loss: 0.7622 Acc: 1.0000\n",
            "Epoch 423/499\n",
            "----------\n",
            "train Loss: 0.7576 Acc: 1.0000\n",
            "val Loss: 0.7621 Acc: 1.0000\n",
            "Epoch 424/499\n",
            "----------\n",
            "train Loss: 0.7588 Acc: 1.0000\n",
            "val Loss: 0.7623 Acc: 1.0000\n",
            "Epoch 425/499\n",
            "----------\n",
            "train Loss: 0.7610 Acc: 1.0000\n",
            "val Loss: 0.7624 Acc: 1.0000\n",
            "Epoch 426/499\n",
            "----------\n",
            "train Loss: 0.7596 Acc: 1.0000\n",
            "val Loss: 0.7618 Acc: 1.0000\n",
            "Epoch 427/499\n",
            "----------\n",
            "train Loss: 0.7607 Acc: 1.0000\n",
            "val Loss: 0.7618 Acc: 1.0000\n",
            "Epoch 428/499\n",
            "----------\n",
            "train Loss: 0.7559 Acc: 1.0000\n",
            "val Loss: 0.7620 Acc: 1.0000\n",
            "Epoch 429/499\n",
            "----------\n",
            "train Loss: 0.7576 Acc: 1.0000\n",
            "val Loss: 0.7621 Acc: 1.0000\n",
            "Epoch 430/499\n",
            "----------\n",
            "train Loss: 0.7610 Acc: 1.0000\n",
            "val Loss: 0.7620 Acc: 1.0000\n",
            "Epoch 431/499\n",
            "----------\n",
            "train Loss: 0.7585 Acc: 1.0000\n",
            "val Loss: 0.7619 Acc: 1.0000\n",
            "Epoch 432/499\n",
            "----------\n",
            "train Loss: 0.7572 Acc: 1.0000\n",
            "val Loss: 0.7622 Acc: 1.0000\n",
            "Epoch 433/499\n",
            "----------\n",
            "train Loss: 0.7566 Acc: 1.0000\n",
            "val Loss: 0.7621 Acc: 1.0000\n",
            "Epoch 434/499\n",
            "----------\n",
            "train Loss: 0.7557 Acc: 1.0000\n",
            "val Loss: 0.7617 Acc: 1.0000\n",
            "Epoch 435/499\n",
            "----------\n",
            "train Loss: 0.7590 Acc: 1.0000\n",
            "val Loss: 0.7617 Acc: 1.0000\n",
            "Epoch 436/499\n",
            "----------\n",
            "train Loss: 0.7558 Acc: 1.0000\n",
            "val Loss: 0.7620 Acc: 1.0000\n",
            "Epoch 437/499\n",
            "----------\n",
            "train Loss: 0.7614 Acc: 1.0000\n",
            "val Loss: 0.7620 Acc: 1.0000\n",
            "Epoch 438/499\n",
            "----------\n",
            "train Loss: 0.7590 Acc: 1.0000\n",
            "val Loss: 0.7620 Acc: 1.0000\n",
            "Epoch 439/499\n",
            "----------\n",
            "train Loss: 0.7569 Acc: 1.0000\n",
            "val Loss: 0.7618 Acc: 1.0000\n",
            "Epoch 440/499\n",
            "----------\n",
            "train Loss: 0.7577 Acc: 1.0000\n",
            "val Loss: 0.7620 Acc: 1.0000\n",
            "Epoch 441/499\n",
            "----------\n",
            "train Loss: 0.7653 Acc: 1.0000\n",
            "val Loss: 0.7621 Acc: 1.0000\n",
            "Epoch 442/499\n",
            "----------\n",
            "train Loss: 0.7572 Acc: 1.0000\n",
            "val Loss: 0.7619 Acc: 1.0000\n",
            "Epoch 443/499\n",
            "----------\n",
            "train Loss: 0.7578 Acc: 1.0000\n",
            "val Loss: 0.7615 Acc: 1.0000\n",
            "Epoch 444/499\n",
            "----------\n",
            "train Loss: 0.7610 Acc: 1.0000\n",
            "val Loss: 0.7614 Acc: 1.0000\n",
            "Epoch 445/499\n",
            "----------\n",
            "train Loss: 0.7567 Acc: 1.0000\n",
            "val Loss: 0.7614 Acc: 1.0000\n",
            "Epoch 446/499\n",
            "----------\n",
            "train Loss: 0.7562 Acc: 1.0000\n",
            "val Loss: 0.7616 Acc: 1.0000\n",
            "Epoch 447/499\n",
            "----------\n",
            "train Loss: 0.7587 Acc: 1.0000\n",
            "val Loss: 0.7616 Acc: 1.0000\n",
            "Epoch 448/499\n",
            "----------\n",
            "train Loss: 0.7575 Acc: 1.0000\n",
            "val Loss: 0.7618 Acc: 1.0000\n",
            "Epoch 449/499\n",
            "----------\n",
            "train Loss: 0.7563 Acc: 1.0000\n",
            "val Loss: 0.7614 Acc: 1.0000\n",
            "Epoch 450/499\n",
            "----------\n",
            "train Loss: 0.7597 Acc: 1.0000\n",
            "val Loss: 0.7612 Acc: 1.0000\n",
            "Epoch 451/499\n",
            "----------\n",
            "train Loss: 0.7557 Acc: 1.0000\n",
            "val Loss: 0.7611 Acc: 1.0000\n",
            "Epoch 452/499\n",
            "----------\n",
            "train Loss: 0.7581 Acc: 1.0000\n",
            "val Loss: 0.7612 Acc: 1.0000\n",
            "Epoch 453/499\n",
            "----------\n",
            "train Loss: 0.7581 Acc: 1.0000\n",
            "val Loss: 0.7611 Acc: 1.0000\n",
            "Epoch 454/499\n",
            "----------\n",
            "train Loss: 0.7647 Acc: 1.0000\n",
            "val Loss: 0.7611 Acc: 1.0000\n",
            "Epoch 455/499\n",
            "----------\n",
            "train Loss: 0.7570 Acc: 1.0000\n",
            "val Loss: 0.7613 Acc: 1.0000\n",
            "Epoch 456/499\n",
            "----------\n",
            "train Loss: 0.7609 Acc: 1.0000\n",
            "val Loss: 0.7611 Acc: 1.0000\n",
            "Epoch 457/499\n",
            "----------\n",
            "train Loss: 0.7600 Acc: 1.0000\n",
            "val Loss: 0.7608 Acc: 1.0000\n",
            "Epoch 458/499\n",
            "----------\n",
            "train Loss: 0.7583 Acc: 1.0000\n",
            "val Loss: 0.7608 Acc: 1.0000\n",
            "Epoch 459/499\n",
            "----------\n",
            "train Loss: 0.7565 Acc: 1.0000\n",
            "val Loss: 0.7608 Acc: 1.0000\n",
            "Epoch 460/499\n",
            "----------\n",
            "train Loss: 0.7544 Acc: 1.0000\n",
            "val Loss: 0.7608 Acc: 1.0000\n",
            "Epoch 461/499\n",
            "----------\n",
            "train Loss: 0.7541 Acc: 1.0000\n",
            "val Loss: 0.7611 Acc: 1.0000\n",
            "Epoch 462/499\n",
            "----------\n",
            "train Loss: 0.7550 Acc: 1.0000\n",
            "val Loss: 0.7610 Acc: 1.0000\n",
            "Epoch 463/499\n",
            "----------\n",
            "train Loss: 0.7546 Acc: 1.0000\n",
            "val Loss: 0.7611 Acc: 1.0000\n",
            "Epoch 464/499\n",
            "----------\n",
            "train Loss: 0.7644 Acc: 1.0000\n",
            "val Loss: 0.7610 Acc: 1.0000\n",
            "Epoch 465/499\n",
            "----------\n",
            "train Loss: 0.7556 Acc: 1.0000\n",
            "val Loss: 0.7609 Acc: 1.0000\n",
            "Epoch 466/499\n",
            "----------\n",
            "train Loss: 0.7570 Acc: 1.0000\n",
            "val Loss: 0.7609 Acc: 1.0000\n",
            "Epoch 467/499\n",
            "----------\n",
            "train Loss: 0.7571 Acc: 1.0000\n",
            "val Loss: 0.7611 Acc: 1.0000\n",
            "Epoch 468/499\n",
            "----------\n",
            "train Loss: 0.7609 Acc: 1.0000\n",
            "val Loss: 0.7611 Acc: 1.0000\n",
            "Epoch 469/499\n",
            "----------\n",
            "train Loss: 0.7597 Acc: 1.0000\n",
            "val Loss: 0.7608 Acc: 1.0000\n",
            "Epoch 470/499\n",
            "----------\n",
            "train Loss: 0.7551 Acc: 1.0000\n",
            "val Loss: 0.7608 Acc: 1.0000\n",
            "Epoch 471/499\n",
            "----------\n",
            "train Loss: 0.7601 Acc: 1.0000\n",
            "val Loss: 0.7608 Acc: 1.0000\n",
            "Epoch 472/499\n",
            "----------\n",
            "train Loss: 0.7619 Acc: 1.0000\n",
            "val Loss: 0.7608 Acc: 1.0000\n",
            "Epoch 473/499\n",
            "----------\n",
            "train Loss: 0.7552 Acc: 1.0000\n",
            "val Loss: 0.7611 Acc: 1.0000\n",
            "Epoch 474/499\n",
            "----------\n",
            "train Loss: 0.7573 Acc: 1.0000\n",
            "val Loss: 0.7612 Acc: 1.0000\n",
            "Epoch 475/499\n",
            "----------\n",
            "train Loss: 0.7551 Acc: 1.0000\n",
            "val Loss: 0.7606 Acc: 1.0000\n",
            "Epoch 476/499\n",
            "----------\n",
            "train Loss: 0.7573 Acc: 1.0000\n",
            "val Loss: 0.7607 Acc: 1.0000\n",
            "Epoch 477/499\n",
            "----------\n",
            "train Loss: 0.7561 Acc: 1.0000\n",
            "val Loss: 0.7608 Acc: 1.0000\n",
            "Epoch 478/499\n",
            "----------\n",
            "train Loss: 0.7566 Acc: 1.0000\n",
            "val Loss: 0.7607 Acc: 1.0000\n",
            "Epoch 479/499\n",
            "----------\n",
            "train Loss: 0.7548 Acc: 1.0000\n",
            "val Loss: 0.7607 Acc: 1.0000\n",
            "Epoch 480/499\n",
            "----------\n",
            "train Loss: 0.7571 Acc: 1.0000\n",
            "val Loss: 0.7607 Acc: 1.0000\n",
            "Epoch 481/499\n",
            "----------\n",
            "train Loss: 0.7567 Acc: 1.0000\n",
            "val Loss: 0.7604 Acc: 1.0000\n",
            "Epoch 482/499\n",
            "----------\n",
            "train Loss: 0.7561 Acc: 1.0000\n",
            "val Loss: 0.7604 Acc: 1.0000\n",
            "Epoch 483/499\n",
            "----------\n",
            "train Loss: 0.7572 Acc: 1.0000\n",
            "val Loss: 0.7603 Acc: 1.0000\n",
            "Epoch 484/499\n",
            "----------\n",
            "train Loss: 0.7551 Acc: 1.0000\n",
            "val Loss: 0.7603 Acc: 1.0000\n",
            "Epoch 485/499\n",
            "----------\n",
            "train Loss: 0.7568 Acc: 1.0000\n",
            "val Loss: 0.7604 Acc: 1.0000\n",
            "Epoch 486/499\n",
            "----------\n",
            "train Loss: 0.7556 Acc: 1.0000\n",
            "val Loss: 0.7603 Acc: 1.0000\n",
            "Epoch 487/499\n",
            "----------\n",
            "train Loss: 0.7550 Acc: 1.0000\n",
            "val Loss: 0.7601 Acc: 1.0000\n",
            "Epoch 488/499\n",
            "----------\n",
            "train Loss: 0.7576 Acc: 1.0000\n",
            "val Loss: 0.7604 Acc: 1.0000\n",
            "Epoch 489/499\n",
            "----------\n",
            "train Loss: 0.7588 Acc: 1.0000\n",
            "val Loss: 0.7604 Acc: 1.0000\n",
            "Epoch 490/499\n",
            "----------\n",
            "train Loss: 0.7550 Acc: 1.0000\n",
            "val Loss: 0.7606 Acc: 1.0000\n",
            "Epoch 491/499\n",
            "----------\n",
            "train Loss: 0.7560 Acc: 1.0000\n",
            "val Loss: 0.7605 Acc: 1.0000\n",
            "Epoch 492/499\n",
            "----------\n",
            "train Loss: 0.7680 Acc: 1.0000\n",
            "val Loss: 0.7602 Acc: 1.0000\n",
            "Epoch 493/499\n",
            "----------\n",
            "train Loss: 0.7556 Acc: 1.0000\n",
            "val Loss: 0.7602 Acc: 1.0000\n",
            "Epoch 494/499\n",
            "----------\n",
            "train Loss: 0.7591 Acc: 1.0000\n",
            "val Loss: 0.7599 Acc: 1.0000\n",
            "Epoch 495/499\n",
            "----------\n",
            "train Loss: 0.7542 Acc: 1.0000\n",
            "val Loss: 0.7601 Acc: 1.0000\n",
            "Epoch 496/499\n",
            "----------\n",
            "train Loss: 0.7560 Acc: 1.0000\n",
            "val Loss: 0.7602 Acc: 1.0000\n",
            "Epoch 497/499\n",
            "----------\n",
            "train Loss: 0.7568 Acc: 1.0000\n",
            "val Loss: 0.7601 Acc: 1.0000\n",
            "Epoch 498/499\n",
            "----------\n",
            "train Loss: 0.7555 Acc: 1.0000\n",
            "val Loss: 0.7602 Acc: 1.0000\n",
            "Epoch 499/499\n",
            "----------\n",
            "train Loss: 0.7538 Acc: 1.0000\n",
            "val Loss: 0.7604 Acc: 1.0000\n",
            "Training complete in 5m 30s\n",
            "Best val Acc: 1.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxPOEnZAUrvR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "traced_model = torch.jit.trace(model_ft.float(), torch.randn(1,3,150,150).to(device))\n",
        "torch.jit.save(traced_model, 'detectMyFace_suman.pt')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysd9KbJgTEgK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6163a883-2f10-4204-e04b-ca2690dbd8f0"
      },
      "source": [
        "from torchsummary import summary\n",
        "summary(model_ft,input_size=(3,150,150))\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 74, 74]             864\n",
            "       BatchNorm2d-2           [-1, 32, 74, 74]              64\n",
            "              ReLU-3           [-1, 32, 74, 74]               0\n",
            "       BasicConv2d-4           [-1, 32, 74, 74]               0\n",
            "            Conv2d-5           [-1, 32, 72, 72]           9,216\n",
            "       BatchNorm2d-6           [-1, 32, 72, 72]              64\n",
            "              ReLU-7           [-1, 32, 72, 72]               0\n",
            "       BasicConv2d-8           [-1, 32, 72, 72]               0\n",
            "            Conv2d-9           [-1, 64, 72, 72]          18,432\n",
            "      BatchNorm2d-10           [-1, 64, 72, 72]             128\n",
            "             ReLU-11           [-1, 64, 72, 72]               0\n",
            "      BasicConv2d-12           [-1, 64, 72, 72]               0\n",
            "        MaxPool2d-13           [-1, 64, 35, 35]               0\n",
            "           Conv2d-14           [-1, 80, 35, 35]           5,120\n",
            "      BatchNorm2d-15           [-1, 80, 35, 35]             160\n",
            "             ReLU-16           [-1, 80, 35, 35]               0\n",
            "      BasicConv2d-17           [-1, 80, 35, 35]               0\n",
            "           Conv2d-18          [-1, 192, 33, 33]         138,240\n",
            "      BatchNorm2d-19          [-1, 192, 33, 33]             384\n",
            "             ReLU-20          [-1, 192, 33, 33]               0\n",
            "      BasicConv2d-21          [-1, 192, 33, 33]               0\n",
            "           Conv2d-22          [-1, 256, 16, 16]         442,368\n",
            "      BatchNorm2d-23          [-1, 256, 16, 16]             512\n",
            "             ReLU-24          [-1, 256, 16, 16]               0\n",
            "      BasicConv2d-25          [-1, 256, 16, 16]               0\n",
            "           Conv2d-26           [-1, 32, 16, 16]           8,192\n",
            "      BatchNorm2d-27           [-1, 32, 16, 16]              64\n",
            "             ReLU-28           [-1, 32, 16, 16]               0\n",
            "      BasicConv2d-29           [-1, 32, 16, 16]               0\n",
            "           Conv2d-30           [-1, 32, 16, 16]           8,192\n",
            "      BatchNorm2d-31           [-1, 32, 16, 16]              64\n",
            "             ReLU-32           [-1, 32, 16, 16]               0\n",
            "      BasicConv2d-33           [-1, 32, 16, 16]               0\n",
            "           Conv2d-34           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-35           [-1, 32, 16, 16]              64\n",
            "             ReLU-36           [-1, 32, 16, 16]               0\n",
            "      BasicConv2d-37           [-1, 32, 16, 16]               0\n",
            "           Conv2d-38           [-1, 32, 16, 16]           8,192\n",
            "      BatchNorm2d-39           [-1, 32, 16, 16]              64\n",
            "             ReLU-40           [-1, 32, 16, 16]               0\n",
            "      BasicConv2d-41           [-1, 32, 16, 16]               0\n",
            "           Conv2d-42           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-43           [-1, 32, 16, 16]              64\n",
            "             ReLU-44           [-1, 32, 16, 16]               0\n",
            "      BasicConv2d-45           [-1, 32, 16, 16]               0\n",
            "           Conv2d-46           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-47           [-1, 32, 16, 16]              64\n",
            "             ReLU-48           [-1, 32, 16, 16]               0\n",
            "      BasicConv2d-49           [-1, 32, 16, 16]               0\n",
            "           Conv2d-50          [-1, 256, 16, 16]          24,832\n",
            "             ReLU-51          [-1, 256, 16, 16]               0\n",
            "          Block35-52          [-1, 256, 16, 16]               0\n",
            "           Conv2d-53           [-1, 32, 16, 16]           8,192\n",
            "      BatchNorm2d-54           [-1, 32, 16, 16]              64\n",
            "             ReLU-55           [-1, 32, 16, 16]               0\n",
            "      BasicConv2d-56           [-1, 32, 16, 16]               0\n",
            "           Conv2d-57           [-1, 32, 16, 16]           8,192\n",
            "      BatchNorm2d-58           [-1, 32, 16, 16]              64\n",
            "             ReLU-59           [-1, 32, 16, 16]               0\n",
            "      BasicConv2d-60           [-1, 32, 16, 16]               0\n",
            "           Conv2d-61           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-62           [-1, 32, 16, 16]              64\n",
            "             ReLU-63           [-1, 32, 16, 16]               0\n",
            "      BasicConv2d-64           [-1, 32, 16, 16]               0\n",
            "           Conv2d-65           [-1, 32, 16, 16]           8,192\n",
            "      BatchNorm2d-66           [-1, 32, 16, 16]              64\n",
            "             ReLU-67           [-1, 32, 16, 16]               0\n",
            "      BasicConv2d-68           [-1, 32, 16, 16]               0\n",
            "           Conv2d-69           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-70           [-1, 32, 16, 16]              64\n",
            "             ReLU-71           [-1, 32, 16, 16]               0\n",
            "      BasicConv2d-72           [-1, 32, 16, 16]               0\n",
            "           Conv2d-73           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-74           [-1, 32, 16, 16]              64\n",
            "             ReLU-75           [-1, 32, 16, 16]               0\n",
            "      BasicConv2d-76           [-1, 32, 16, 16]               0\n",
            "           Conv2d-77          [-1, 256, 16, 16]          24,832\n",
            "             ReLU-78          [-1, 256, 16, 16]               0\n",
            "          Block35-79          [-1, 256, 16, 16]               0\n",
            "           Conv2d-80           [-1, 32, 16, 16]           8,192\n",
            "      BatchNorm2d-81           [-1, 32, 16, 16]              64\n",
            "             ReLU-82           [-1, 32, 16, 16]               0\n",
            "      BasicConv2d-83           [-1, 32, 16, 16]               0\n",
            "           Conv2d-84           [-1, 32, 16, 16]           8,192\n",
            "      BatchNorm2d-85           [-1, 32, 16, 16]              64\n",
            "             ReLU-86           [-1, 32, 16, 16]               0\n",
            "      BasicConv2d-87           [-1, 32, 16, 16]               0\n",
            "           Conv2d-88           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-89           [-1, 32, 16, 16]              64\n",
            "             ReLU-90           [-1, 32, 16, 16]               0\n",
            "      BasicConv2d-91           [-1, 32, 16, 16]               0\n",
            "           Conv2d-92           [-1, 32, 16, 16]           8,192\n",
            "      BatchNorm2d-93           [-1, 32, 16, 16]              64\n",
            "             ReLU-94           [-1, 32, 16, 16]               0\n",
            "      BasicConv2d-95           [-1, 32, 16, 16]               0\n",
            "           Conv2d-96           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-97           [-1, 32, 16, 16]              64\n",
            "             ReLU-98           [-1, 32, 16, 16]               0\n",
            "      BasicConv2d-99           [-1, 32, 16, 16]               0\n",
            "          Conv2d-100           [-1, 32, 16, 16]           9,216\n",
            "     BatchNorm2d-101           [-1, 32, 16, 16]              64\n",
            "            ReLU-102           [-1, 32, 16, 16]               0\n",
            "     BasicConv2d-103           [-1, 32, 16, 16]               0\n",
            "          Conv2d-104          [-1, 256, 16, 16]          24,832\n",
            "            ReLU-105          [-1, 256, 16, 16]               0\n",
            "         Block35-106          [-1, 256, 16, 16]               0\n",
            "          Conv2d-107           [-1, 32, 16, 16]           8,192\n",
            "     BatchNorm2d-108           [-1, 32, 16, 16]              64\n",
            "            ReLU-109           [-1, 32, 16, 16]               0\n",
            "     BasicConv2d-110           [-1, 32, 16, 16]               0\n",
            "          Conv2d-111           [-1, 32, 16, 16]           8,192\n",
            "     BatchNorm2d-112           [-1, 32, 16, 16]              64\n",
            "            ReLU-113           [-1, 32, 16, 16]               0\n",
            "     BasicConv2d-114           [-1, 32, 16, 16]               0\n",
            "          Conv2d-115           [-1, 32, 16, 16]           9,216\n",
            "     BatchNorm2d-116           [-1, 32, 16, 16]              64\n",
            "            ReLU-117           [-1, 32, 16, 16]               0\n",
            "     BasicConv2d-118           [-1, 32, 16, 16]               0\n",
            "          Conv2d-119           [-1, 32, 16, 16]           8,192\n",
            "     BatchNorm2d-120           [-1, 32, 16, 16]              64\n",
            "            ReLU-121           [-1, 32, 16, 16]               0\n",
            "     BasicConv2d-122           [-1, 32, 16, 16]               0\n",
            "          Conv2d-123           [-1, 32, 16, 16]           9,216\n",
            "     BatchNorm2d-124           [-1, 32, 16, 16]              64\n",
            "            ReLU-125           [-1, 32, 16, 16]               0\n",
            "     BasicConv2d-126           [-1, 32, 16, 16]               0\n",
            "          Conv2d-127           [-1, 32, 16, 16]           9,216\n",
            "     BatchNorm2d-128           [-1, 32, 16, 16]              64\n",
            "            ReLU-129           [-1, 32, 16, 16]               0\n",
            "     BasicConv2d-130           [-1, 32, 16, 16]               0\n",
            "          Conv2d-131          [-1, 256, 16, 16]          24,832\n",
            "            ReLU-132          [-1, 256, 16, 16]               0\n",
            "         Block35-133          [-1, 256, 16, 16]               0\n",
            "          Conv2d-134           [-1, 32, 16, 16]           8,192\n",
            "     BatchNorm2d-135           [-1, 32, 16, 16]              64\n",
            "            ReLU-136           [-1, 32, 16, 16]               0\n",
            "     BasicConv2d-137           [-1, 32, 16, 16]               0\n",
            "          Conv2d-138           [-1, 32, 16, 16]           8,192\n",
            "     BatchNorm2d-139           [-1, 32, 16, 16]              64\n",
            "            ReLU-140           [-1, 32, 16, 16]               0\n",
            "     BasicConv2d-141           [-1, 32, 16, 16]               0\n",
            "          Conv2d-142           [-1, 32, 16, 16]           9,216\n",
            "     BatchNorm2d-143           [-1, 32, 16, 16]              64\n",
            "            ReLU-144           [-1, 32, 16, 16]               0\n",
            "     BasicConv2d-145           [-1, 32, 16, 16]               0\n",
            "          Conv2d-146           [-1, 32, 16, 16]           8,192\n",
            "     BatchNorm2d-147           [-1, 32, 16, 16]              64\n",
            "            ReLU-148           [-1, 32, 16, 16]               0\n",
            "     BasicConv2d-149           [-1, 32, 16, 16]               0\n",
            "          Conv2d-150           [-1, 32, 16, 16]           9,216\n",
            "     BatchNorm2d-151           [-1, 32, 16, 16]              64\n",
            "            ReLU-152           [-1, 32, 16, 16]               0\n",
            "     BasicConv2d-153           [-1, 32, 16, 16]               0\n",
            "          Conv2d-154           [-1, 32, 16, 16]           9,216\n",
            "     BatchNorm2d-155           [-1, 32, 16, 16]              64\n",
            "            ReLU-156           [-1, 32, 16, 16]               0\n",
            "     BasicConv2d-157           [-1, 32, 16, 16]               0\n",
            "          Conv2d-158          [-1, 256, 16, 16]          24,832\n",
            "            ReLU-159          [-1, 256, 16, 16]               0\n",
            "         Block35-160          [-1, 256, 16, 16]               0\n",
            "          Conv2d-161            [-1, 384, 7, 7]         884,736\n",
            "     BatchNorm2d-162            [-1, 384, 7, 7]             768\n",
            "            ReLU-163            [-1, 384, 7, 7]               0\n",
            "     BasicConv2d-164            [-1, 384, 7, 7]               0\n",
            "          Conv2d-165          [-1, 192, 16, 16]          49,152\n",
            "     BatchNorm2d-166          [-1, 192, 16, 16]             384\n",
            "            ReLU-167          [-1, 192, 16, 16]               0\n",
            "     BasicConv2d-168          [-1, 192, 16, 16]               0\n",
            "          Conv2d-169          [-1, 192, 16, 16]         331,776\n",
            "     BatchNorm2d-170          [-1, 192, 16, 16]             384\n",
            "            ReLU-171          [-1, 192, 16, 16]               0\n",
            "     BasicConv2d-172          [-1, 192, 16, 16]               0\n",
            "          Conv2d-173            [-1, 256, 7, 7]         442,368\n",
            "     BatchNorm2d-174            [-1, 256, 7, 7]             512\n",
            "            ReLU-175            [-1, 256, 7, 7]               0\n",
            "     BasicConv2d-176            [-1, 256, 7, 7]               0\n",
            "       MaxPool2d-177            [-1, 256, 7, 7]               0\n",
            "        Mixed_6a-178            [-1, 896, 7, 7]               0\n",
            "          Conv2d-179            [-1, 128, 7, 7]         114,688\n",
            "     BatchNorm2d-180            [-1, 128, 7, 7]             256\n",
            "            ReLU-181            [-1, 128, 7, 7]               0\n",
            "     BasicConv2d-182            [-1, 128, 7, 7]               0\n",
            "          Conv2d-183            [-1, 128, 7, 7]         114,688\n",
            "     BatchNorm2d-184            [-1, 128, 7, 7]             256\n",
            "            ReLU-185            [-1, 128, 7, 7]               0\n",
            "     BasicConv2d-186            [-1, 128, 7, 7]               0\n",
            "          Conv2d-187            [-1, 128, 7, 7]         114,688\n",
            "     BatchNorm2d-188            [-1, 128, 7, 7]             256\n",
            "            ReLU-189            [-1, 128, 7, 7]               0\n",
            "     BasicConv2d-190            [-1, 128, 7, 7]               0\n",
            "          Conv2d-191            [-1, 128, 7, 7]         114,688\n",
            "     BatchNorm2d-192            [-1, 128, 7, 7]             256\n",
            "            ReLU-193            [-1, 128, 7, 7]               0\n",
            "     BasicConv2d-194            [-1, 128, 7, 7]               0\n",
            "          Conv2d-195            [-1, 896, 7, 7]         230,272\n",
            "            ReLU-196            [-1, 896, 7, 7]               0\n",
            "         Block17-197            [-1, 896, 7, 7]               0\n",
            "          Conv2d-198            [-1, 128, 7, 7]         114,688\n",
            "     BatchNorm2d-199            [-1, 128, 7, 7]             256\n",
            "            ReLU-200            [-1, 128, 7, 7]               0\n",
            "     BasicConv2d-201            [-1, 128, 7, 7]               0\n",
            "          Conv2d-202            [-1, 128, 7, 7]         114,688\n",
            "     BatchNorm2d-203            [-1, 128, 7, 7]             256\n",
            "            ReLU-204            [-1, 128, 7, 7]               0\n",
            "     BasicConv2d-205            [-1, 128, 7, 7]               0\n",
            "          Conv2d-206            [-1, 128, 7, 7]         114,688\n",
            "     BatchNorm2d-207            [-1, 128, 7, 7]             256\n",
            "            ReLU-208            [-1, 128, 7, 7]               0\n",
            "     BasicConv2d-209            [-1, 128, 7, 7]               0\n",
            "          Conv2d-210            [-1, 128, 7, 7]         114,688\n",
            "     BatchNorm2d-211            [-1, 128, 7, 7]             256\n",
            "            ReLU-212            [-1, 128, 7, 7]               0\n",
            "     BasicConv2d-213            [-1, 128, 7, 7]               0\n",
            "          Conv2d-214            [-1, 896, 7, 7]         230,272\n",
            "            ReLU-215            [-1, 896, 7, 7]               0\n",
            "         Block17-216            [-1, 896, 7, 7]               0\n",
            "          Conv2d-217            [-1, 128, 7, 7]         114,688\n",
            "     BatchNorm2d-218            [-1, 128, 7, 7]             256\n",
            "            ReLU-219            [-1, 128, 7, 7]               0\n",
            "     BasicConv2d-220            [-1, 128, 7, 7]               0\n",
            "          Conv2d-221            [-1, 128, 7, 7]         114,688\n",
            "     BatchNorm2d-222            [-1, 128, 7, 7]             256\n",
            "            ReLU-223            [-1, 128, 7, 7]               0\n",
            "     BasicConv2d-224            [-1, 128, 7, 7]               0\n",
            "          Conv2d-225            [-1, 128, 7, 7]         114,688\n",
            "     BatchNorm2d-226            [-1, 128, 7, 7]             256\n",
            "            ReLU-227            [-1, 128, 7, 7]               0\n",
            "     BasicConv2d-228            [-1, 128, 7, 7]               0\n",
            "          Conv2d-229            [-1, 128, 7, 7]         114,688\n",
            "     BatchNorm2d-230            [-1, 128, 7, 7]             256\n",
            "            ReLU-231            [-1, 128, 7, 7]               0\n",
            "     BasicConv2d-232            [-1, 128, 7, 7]               0\n",
            "          Conv2d-233            [-1, 896, 7, 7]         230,272\n",
            "            ReLU-234            [-1, 896, 7, 7]               0\n",
            "         Block17-235            [-1, 896, 7, 7]               0\n",
            "          Conv2d-236            [-1, 128, 7, 7]         114,688\n",
            "     BatchNorm2d-237            [-1, 128, 7, 7]             256\n",
            "            ReLU-238            [-1, 128, 7, 7]               0\n",
            "     BasicConv2d-239            [-1, 128, 7, 7]               0\n",
            "          Conv2d-240            [-1, 128, 7, 7]         114,688\n",
            "     BatchNorm2d-241            [-1, 128, 7, 7]             256\n",
            "            ReLU-242            [-1, 128, 7, 7]               0\n",
            "     BasicConv2d-243            [-1, 128, 7, 7]               0\n",
            "          Conv2d-244            [-1, 128, 7, 7]         114,688\n",
            "     BatchNorm2d-245            [-1, 128, 7, 7]             256\n",
            "            ReLU-246            [-1, 128, 7, 7]               0\n",
            "     BasicConv2d-247            [-1, 128, 7, 7]               0\n",
            "          Conv2d-248            [-1, 128, 7, 7]         114,688\n",
            "     BatchNorm2d-249            [-1, 128, 7, 7]             256\n",
            "            ReLU-250            [-1, 128, 7, 7]               0\n",
            "     BasicConv2d-251            [-1, 128, 7, 7]               0\n",
            "          Conv2d-252            [-1, 896, 7, 7]         230,272\n",
            "            ReLU-253            [-1, 896, 7, 7]               0\n",
            "         Block17-254            [-1, 896, 7, 7]               0\n",
            "          Conv2d-255            [-1, 128, 7, 7]         114,688\n",
            "     BatchNorm2d-256            [-1, 128, 7, 7]             256\n",
            "            ReLU-257            [-1, 128, 7, 7]               0\n",
            "     BasicConv2d-258            [-1, 128, 7, 7]               0\n",
            "          Conv2d-259            [-1, 128, 7, 7]         114,688\n",
            "     BatchNorm2d-260            [-1, 128, 7, 7]             256\n",
            "            ReLU-261            [-1, 128, 7, 7]               0\n",
            "     BasicConv2d-262            [-1, 128, 7, 7]               0\n",
            "          Conv2d-263            [-1, 128, 7, 7]         114,688\n",
            "     BatchNorm2d-264            [-1, 128, 7, 7]             256\n",
            "            ReLU-265            [-1, 128, 7, 7]               0\n",
            "     BasicConv2d-266            [-1, 128, 7, 7]               0\n",
            "          Conv2d-267            [-1, 128, 7, 7]         114,688\n",
            "     BatchNorm2d-268            [-1, 128, 7, 7]             256\n",
            "            ReLU-269            [-1, 128, 7, 7]               0\n",
            "     BasicConv2d-270            [-1, 128, 7, 7]               0\n",
            "          Conv2d-271            [-1, 896, 7, 7]         230,272\n",
            "            ReLU-272            [-1, 896, 7, 7]               0\n",
            "         Block17-273            [-1, 896, 7, 7]               0\n",
            "          Conv2d-274            [-1, 128, 7, 7]         114,688\n",
            "     BatchNorm2d-275            [-1, 128, 7, 7]             256\n",
            "            ReLU-276            [-1, 128, 7, 7]               0\n",
            "     BasicConv2d-277            [-1, 128, 7, 7]               0\n",
            "          Conv2d-278            [-1, 128, 7, 7]         114,688\n",
            "     BatchNorm2d-279            [-1, 128, 7, 7]             256\n",
            "            ReLU-280            [-1, 128, 7, 7]               0\n",
            "     BasicConv2d-281            [-1, 128, 7, 7]               0\n",
            "          Conv2d-282            [-1, 128, 7, 7]         114,688\n",
            "     BatchNorm2d-283            [-1, 128, 7, 7]             256\n",
            "            ReLU-284            [-1, 128, 7, 7]               0\n",
            "     BasicConv2d-285            [-1, 128, 7, 7]               0\n",
            "          Conv2d-286            [-1, 128, 7, 7]         114,688\n",
            "     BatchNorm2d-287            [-1, 128, 7, 7]             256\n",
            "            ReLU-288            [-1, 128, 7, 7]               0\n",
            "     BasicConv2d-289            [-1, 128, 7, 7]               0\n",
            "          Conv2d-290            [-1, 896, 7, 7]         230,272\n",
            "            ReLU-291            [-1, 896, 7, 7]               0\n",
            "         Block17-292            [-1, 896, 7, 7]               0\n",
            "          Conv2d-293            [-1, 128, 7, 7]         114,688\n",
            "     BatchNorm2d-294            [-1, 128, 7, 7]             256\n",
            "            ReLU-295            [-1, 128, 7, 7]               0\n",
            "     BasicConv2d-296            [-1, 128, 7, 7]               0\n",
            "          Conv2d-297            [-1, 128, 7, 7]         114,688\n",
            "     BatchNorm2d-298            [-1, 128, 7, 7]             256\n",
            "            ReLU-299            [-1, 128, 7, 7]               0\n",
            "     BasicConv2d-300            [-1, 128, 7, 7]               0\n",
            "          Conv2d-301            [-1, 128, 7, 7]         114,688\n",
            "     BatchNorm2d-302            [-1, 128, 7, 7]             256\n",
            "            ReLU-303            [-1, 128, 7, 7]               0\n",
            "     BasicConv2d-304            [-1, 128, 7, 7]               0\n",
            "          Conv2d-305            [-1, 128, 7, 7]         114,688\n",
            "     BatchNorm2d-306            [-1, 128, 7, 7]             256\n",
            "            ReLU-307            [-1, 128, 7, 7]               0\n",
            "     BasicConv2d-308            [-1, 128, 7, 7]               0\n",
            "          Conv2d-309            [-1, 896, 7, 7]         230,272\n",
            "            ReLU-310            [-1, 896, 7, 7]               0\n",
            "         Block17-311            [-1, 896, 7, 7]               0\n",
            "          Conv2d-312            [-1, 128, 7, 7]         114,688\n",
            "     BatchNorm2d-313            [-1, 128, 7, 7]             256\n",
            "            ReLU-314            [-1, 128, 7, 7]               0\n",
            "     BasicConv2d-315            [-1, 128, 7, 7]               0\n",
            "          Conv2d-316            [-1, 128, 7, 7]         114,688\n",
            "     BatchNorm2d-317            [-1, 128, 7, 7]             256\n",
            "            ReLU-318            [-1, 128, 7, 7]               0\n",
            "     BasicConv2d-319            [-1, 128, 7, 7]               0\n",
            "          Conv2d-320            [-1, 128, 7, 7]         114,688\n",
            "     BatchNorm2d-321            [-1, 128, 7, 7]             256\n",
            "            ReLU-322            [-1, 128, 7, 7]               0\n",
            "     BasicConv2d-323            [-1, 128, 7, 7]               0\n",
            "          Conv2d-324            [-1, 128, 7, 7]         114,688\n",
            "     BatchNorm2d-325            [-1, 128, 7, 7]             256\n",
            "            ReLU-326            [-1, 128, 7, 7]               0\n",
            "     BasicConv2d-327            [-1, 128, 7, 7]               0\n",
            "          Conv2d-328            [-1, 896, 7, 7]         230,272\n",
            "            ReLU-329            [-1, 896, 7, 7]               0\n",
            "         Block17-330            [-1, 896, 7, 7]               0\n",
            "          Conv2d-331            [-1, 128, 7, 7]         114,688\n",
            "     BatchNorm2d-332            [-1, 128, 7, 7]             256\n",
            "            ReLU-333            [-1, 128, 7, 7]               0\n",
            "     BasicConv2d-334            [-1, 128, 7, 7]               0\n",
            "          Conv2d-335            [-1, 128, 7, 7]         114,688\n",
            "     BatchNorm2d-336            [-1, 128, 7, 7]             256\n",
            "            ReLU-337            [-1, 128, 7, 7]               0\n",
            "     BasicConv2d-338            [-1, 128, 7, 7]               0\n",
            "          Conv2d-339            [-1, 128, 7, 7]         114,688\n",
            "     BatchNorm2d-340            [-1, 128, 7, 7]             256\n",
            "            ReLU-341            [-1, 128, 7, 7]               0\n",
            "     BasicConv2d-342            [-1, 128, 7, 7]               0\n",
            "          Conv2d-343            [-1, 128, 7, 7]         114,688\n",
            "     BatchNorm2d-344            [-1, 128, 7, 7]             256\n",
            "            ReLU-345            [-1, 128, 7, 7]               0\n",
            "     BasicConv2d-346            [-1, 128, 7, 7]               0\n",
            "          Conv2d-347            [-1, 896, 7, 7]         230,272\n",
            "            ReLU-348            [-1, 896, 7, 7]               0\n",
            "         Block17-349            [-1, 896, 7, 7]               0\n",
            "          Conv2d-350            [-1, 128, 7, 7]         114,688\n",
            "     BatchNorm2d-351            [-1, 128, 7, 7]             256\n",
            "            ReLU-352            [-1, 128, 7, 7]               0\n",
            "     BasicConv2d-353            [-1, 128, 7, 7]               0\n",
            "          Conv2d-354            [-1, 128, 7, 7]         114,688\n",
            "     BatchNorm2d-355            [-1, 128, 7, 7]             256\n",
            "            ReLU-356            [-1, 128, 7, 7]               0\n",
            "     BasicConv2d-357            [-1, 128, 7, 7]               0\n",
            "          Conv2d-358            [-1, 128, 7, 7]         114,688\n",
            "     BatchNorm2d-359            [-1, 128, 7, 7]             256\n",
            "            ReLU-360            [-1, 128, 7, 7]               0\n",
            "     BasicConv2d-361            [-1, 128, 7, 7]               0\n",
            "          Conv2d-362            [-1, 128, 7, 7]         114,688\n",
            "     BatchNorm2d-363            [-1, 128, 7, 7]             256\n",
            "            ReLU-364            [-1, 128, 7, 7]               0\n",
            "     BasicConv2d-365            [-1, 128, 7, 7]               0\n",
            "          Conv2d-366            [-1, 896, 7, 7]         230,272\n",
            "            ReLU-367            [-1, 896, 7, 7]               0\n",
            "         Block17-368            [-1, 896, 7, 7]               0\n",
            "          Conv2d-369            [-1, 256, 7, 7]         229,376\n",
            "     BatchNorm2d-370            [-1, 256, 7, 7]             512\n",
            "            ReLU-371            [-1, 256, 7, 7]               0\n",
            "     BasicConv2d-372            [-1, 256, 7, 7]               0\n",
            "          Conv2d-373            [-1, 384, 3, 3]         884,736\n",
            "     BatchNorm2d-374            [-1, 384, 3, 3]             768\n",
            "            ReLU-375            [-1, 384, 3, 3]               0\n",
            "     BasicConv2d-376            [-1, 384, 3, 3]               0\n",
            "          Conv2d-377            [-1, 256, 7, 7]         229,376\n",
            "     BatchNorm2d-378            [-1, 256, 7, 7]             512\n",
            "            ReLU-379            [-1, 256, 7, 7]               0\n",
            "     BasicConv2d-380            [-1, 256, 7, 7]               0\n",
            "          Conv2d-381            [-1, 256, 3, 3]         589,824\n",
            "     BatchNorm2d-382            [-1, 256, 3, 3]             512\n",
            "            ReLU-383            [-1, 256, 3, 3]               0\n",
            "     BasicConv2d-384            [-1, 256, 3, 3]               0\n",
            "          Conv2d-385            [-1, 256, 7, 7]         229,376\n",
            "     BatchNorm2d-386            [-1, 256, 7, 7]             512\n",
            "            ReLU-387            [-1, 256, 7, 7]               0\n",
            "     BasicConv2d-388            [-1, 256, 7, 7]               0\n",
            "          Conv2d-389            [-1, 256, 7, 7]         589,824\n",
            "     BatchNorm2d-390            [-1, 256, 7, 7]             512\n",
            "            ReLU-391            [-1, 256, 7, 7]               0\n",
            "     BasicConv2d-392            [-1, 256, 7, 7]               0\n",
            "          Conv2d-393            [-1, 256, 3, 3]         589,824\n",
            "     BatchNorm2d-394            [-1, 256, 3, 3]             512\n",
            "            ReLU-395            [-1, 256, 3, 3]               0\n",
            "     BasicConv2d-396            [-1, 256, 3, 3]               0\n",
            "       MaxPool2d-397            [-1, 896, 3, 3]               0\n",
            "        Mixed_7a-398           [-1, 1792, 3, 3]               0\n",
            "          Conv2d-399            [-1, 192, 3, 3]         344,064\n",
            "     BatchNorm2d-400            [-1, 192, 3, 3]             384\n",
            "            ReLU-401            [-1, 192, 3, 3]               0\n",
            "     BasicConv2d-402            [-1, 192, 3, 3]               0\n",
            "          Conv2d-403            [-1, 192, 3, 3]         344,064\n",
            "     BatchNorm2d-404            [-1, 192, 3, 3]             384\n",
            "            ReLU-405            [-1, 192, 3, 3]               0\n",
            "     BasicConv2d-406            [-1, 192, 3, 3]               0\n",
            "          Conv2d-407            [-1, 192, 3, 3]         110,592\n",
            "     BatchNorm2d-408            [-1, 192, 3, 3]             384\n",
            "            ReLU-409            [-1, 192, 3, 3]               0\n",
            "     BasicConv2d-410            [-1, 192, 3, 3]               0\n",
            "          Conv2d-411            [-1, 192, 3, 3]         110,592\n",
            "     BatchNorm2d-412            [-1, 192, 3, 3]             384\n",
            "            ReLU-413            [-1, 192, 3, 3]               0\n",
            "     BasicConv2d-414            [-1, 192, 3, 3]               0\n",
            "          Conv2d-415           [-1, 1792, 3, 3]         689,920\n",
            "            ReLU-416           [-1, 1792, 3, 3]               0\n",
            "          Block8-417           [-1, 1792, 3, 3]               0\n",
            "          Conv2d-418            [-1, 192, 3, 3]         344,064\n",
            "     BatchNorm2d-419            [-1, 192, 3, 3]             384\n",
            "            ReLU-420            [-1, 192, 3, 3]               0\n",
            "     BasicConv2d-421            [-1, 192, 3, 3]               0\n",
            "          Conv2d-422            [-1, 192, 3, 3]         344,064\n",
            "     BatchNorm2d-423            [-1, 192, 3, 3]             384\n",
            "            ReLU-424            [-1, 192, 3, 3]               0\n",
            "     BasicConv2d-425            [-1, 192, 3, 3]               0\n",
            "          Conv2d-426            [-1, 192, 3, 3]         110,592\n",
            "     BatchNorm2d-427            [-1, 192, 3, 3]             384\n",
            "            ReLU-428            [-1, 192, 3, 3]               0\n",
            "     BasicConv2d-429            [-1, 192, 3, 3]               0\n",
            "          Conv2d-430            [-1, 192, 3, 3]         110,592\n",
            "     BatchNorm2d-431            [-1, 192, 3, 3]             384\n",
            "            ReLU-432            [-1, 192, 3, 3]               0\n",
            "     BasicConv2d-433            [-1, 192, 3, 3]               0\n",
            "          Conv2d-434           [-1, 1792, 3, 3]         689,920\n",
            "            ReLU-435           [-1, 1792, 3, 3]               0\n",
            "          Block8-436           [-1, 1792, 3, 3]               0\n",
            "          Conv2d-437            [-1, 192, 3, 3]         344,064\n",
            "     BatchNorm2d-438            [-1, 192, 3, 3]             384\n",
            "            ReLU-439            [-1, 192, 3, 3]               0\n",
            "     BasicConv2d-440            [-1, 192, 3, 3]               0\n",
            "          Conv2d-441            [-1, 192, 3, 3]         344,064\n",
            "     BatchNorm2d-442            [-1, 192, 3, 3]             384\n",
            "            ReLU-443            [-1, 192, 3, 3]               0\n",
            "     BasicConv2d-444            [-1, 192, 3, 3]               0\n",
            "          Conv2d-445            [-1, 192, 3, 3]         110,592\n",
            "     BatchNorm2d-446            [-1, 192, 3, 3]             384\n",
            "            ReLU-447            [-1, 192, 3, 3]               0\n",
            "     BasicConv2d-448            [-1, 192, 3, 3]               0\n",
            "          Conv2d-449            [-1, 192, 3, 3]         110,592\n",
            "     BatchNorm2d-450            [-1, 192, 3, 3]             384\n",
            "            ReLU-451            [-1, 192, 3, 3]               0\n",
            "     BasicConv2d-452            [-1, 192, 3, 3]               0\n",
            "          Conv2d-453           [-1, 1792, 3, 3]         689,920\n",
            "            ReLU-454           [-1, 1792, 3, 3]               0\n",
            "          Block8-455           [-1, 1792, 3, 3]               0\n",
            "          Conv2d-456            [-1, 192, 3, 3]         344,064\n",
            "     BatchNorm2d-457            [-1, 192, 3, 3]             384\n",
            "            ReLU-458            [-1, 192, 3, 3]               0\n",
            "     BasicConv2d-459            [-1, 192, 3, 3]               0\n",
            "          Conv2d-460            [-1, 192, 3, 3]         344,064\n",
            "     BatchNorm2d-461            [-1, 192, 3, 3]             384\n",
            "            ReLU-462            [-1, 192, 3, 3]               0\n",
            "     BasicConv2d-463            [-1, 192, 3, 3]               0\n",
            "          Conv2d-464            [-1, 192, 3, 3]         110,592\n",
            "     BatchNorm2d-465            [-1, 192, 3, 3]             384\n",
            "            ReLU-466            [-1, 192, 3, 3]               0\n",
            "     BasicConv2d-467            [-1, 192, 3, 3]               0\n",
            "          Conv2d-468            [-1, 192, 3, 3]         110,592\n",
            "     BatchNorm2d-469            [-1, 192, 3, 3]             384\n",
            "            ReLU-470            [-1, 192, 3, 3]               0\n",
            "     BasicConv2d-471            [-1, 192, 3, 3]               0\n",
            "          Conv2d-472           [-1, 1792, 3, 3]         689,920\n",
            "            ReLU-473           [-1, 1792, 3, 3]               0\n",
            "          Block8-474           [-1, 1792, 3, 3]               0\n",
            "          Conv2d-475            [-1, 192, 3, 3]         344,064\n",
            "     BatchNorm2d-476            [-1, 192, 3, 3]             384\n",
            "            ReLU-477            [-1, 192, 3, 3]               0\n",
            "     BasicConv2d-478            [-1, 192, 3, 3]               0\n",
            "          Conv2d-479            [-1, 192, 3, 3]         344,064\n",
            "     BatchNorm2d-480            [-1, 192, 3, 3]             384\n",
            "            ReLU-481            [-1, 192, 3, 3]               0\n",
            "     BasicConv2d-482            [-1, 192, 3, 3]               0\n",
            "          Conv2d-483            [-1, 192, 3, 3]         110,592\n",
            "     BatchNorm2d-484            [-1, 192, 3, 3]             384\n",
            "            ReLU-485            [-1, 192, 3, 3]               0\n",
            "     BasicConv2d-486            [-1, 192, 3, 3]               0\n",
            "          Conv2d-487            [-1, 192, 3, 3]         110,592\n",
            "     BatchNorm2d-488            [-1, 192, 3, 3]             384\n",
            "            ReLU-489            [-1, 192, 3, 3]               0\n",
            "     BasicConv2d-490            [-1, 192, 3, 3]               0\n",
            "          Conv2d-491           [-1, 1792, 3, 3]         689,920\n",
            "            ReLU-492           [-1, 1792, 3, 3]               0\n",
            "          Block8-493           [-1, 1792, 3, 3]               0\n",
            "          Conv2d-494            [-1, 192, 3, 3]         344,064\n",
            "     BatchNorm2d-495            [-1, 192, 3, 3]             384\n",
            "            ReLU-496            [-1, 192, 3, 3]               0\n",
            "     BasicConv2d-497            [-1, 192, 3, 3]               0\n",
            "          Conv2d-498            [-1, 192, 3, 3]         344,064\n",
            "     BatchNorm2d-499            [-1, 192, 3, 3]             384\n",
            "            ReLU-500            [-1, 192, 3, 3]               0\n",
            "     BasicConv2d-501            [-1, 192, 3, 3]               0\n",
            "          Conv2d-502            [-1, 192, 3, 3]         110,592\n",
            "     BatchNorm2d-503            [-1, 192, 3, 3]             384\n",
            "            ReLU-504            [-1, 192, 3, 3]               0\n",
            "     BasicConv2d-505            [-1, 192, 3, 3]               0\n",
            "          Conv2d-506            [-1, 192, 3, 3]         110,592\n",
            "     BatchNorm2d-507            [-1, 192, 3, 3]             384\n",
            "            ReLU-508            [-1, 192, 3, 3]               0\n",
            "     BasicConv2d-509            [-1, 192, 3, 3]               0\n",
            "          Conv2d-510           [-1, 1792, 3, 3]         689,920\n",
            "          Block8-511           [-1, 1792, 3, 3]               0\n",
            "AdaptiveAvgPool2d-512           [-1, 1792, 1, 1]               0\n",
            "         Flatten-513                 [-1, 1792]               0\n",
            "          Linear-514                  [-1, 512]         917,504\n",
            "       normalize-515                  [-1, 512]               0\n",
            "          Linear-516                    [-1, 4]           2,052\n",
            "         Softmax-517                    [-1, 4]               0\n",
            "================================================================\n",
            "Total params: 23,483,652\n",
            "Trainable params: 919,556\n",
            "Non-trainable params: 22,564,096\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.26\n",
            "Forward/backward pass size (MB): 74.95\n",
            "Params size (MB): 89.58\n",
            "Estimated Total Size (MB): 164.79\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwLYso_5XBKS",
        "colab_type": "text"
      },
      "source": [
        "# Load the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9HtoPDWVBVg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "41a71e39-5210-4c5e-b771-98329403cd67"
      },
      "source": [
        "model_test = torch.jit.load('/content/drive/My Drive/EVA4/phase2/s4_faceRecognition/detectMyFace_project/detectMyFace_suman.pt')\n",
        "list(model_test.children())"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[RecursiveScriptModule(\n",
              "   original_name=BasicConv2d\n",
              "   (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "   (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "   (relu): RecursiveScriptModule(original_name=ReLU)\n",
              " ), RecursiveScriptModule(\n",
              "   original_name=BasicConv2d\n",
              "   (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "   (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "   (relu): RecursiveScriptModule(original_name=ReLU)\n",
              " ), RecursiveScriptModule(\n",
              "   original_name=BasicConv2d\n",
              "   (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "   (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "   (relu): RecursiveScriptModule(original_name=ReLU)\n",
              " ), RecursiveScriptModule(original_name=MaxPool2d), RecursiveScriptModule(\n",
              "   original_name=BasicConv2d\n",
              "   (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "   (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "   (relu): RecursiveScriptModule(original_name=ReLU)\n",
              " ), RecursiveScriptModule(\n",
              "   original_name=BasicConv2d\n",
              "   (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "   (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "   (relu): RecursiveScriptModule(original_name=ReLU)\n",
              " ), RecursiveScriptModule(\n",
              "   original_name=BasicConv2d\n",
              "   (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "   (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "   (relu): RecursiveScriptModule(original_name=ReLU)\n",
              " ), RecursiveScriptModule(\n",
              "   original_name=Sequential\n",
              "   (0): RecursiveScriptModule(\n",
              "     original_name=Block35\n",
              "     (branch0): RecursiveScriptModule(\n",
              "       original_name=BasicConv2d\n",
              "       (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "       (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "       (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "     )\n",
              "     (branch1): RecursiveScriptModule(\n",
              "       original_name=Sequential\n",
              "       (0): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "       (1): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "     )\n",
              "     (branch2): RecursiveScriptModule(\n",
              "       original_name=Sequential\n",
              "       (0): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "       (1): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "       (2): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "     )\n",
              "     (conv2d): RecursiveScriptModule(original_name=Conv2d)\n",
              "     (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "   )\n",
              "   (1): RecursiveScriptModule(\n",
              "     original_name=Block35\n",
              "     (branch0): RecursiveScriptModule(\n",
              "       original_name=BasicConv2d\n",
              "       (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "       (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "       (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "     )\n",
              "     (branch1): RecursiveScriptModule(\n",
              "       original_name=Sequential\n",
              "       (0): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "       (1): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "     )\n",
              "     (branch2): RecursiveScriptModule(\n",
              "       original_name=Sequential\n",
              "       (0): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "       (1): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "       (2): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "     )\n",
              "     (conv2d): RecursiveScriptModule(original_name=Conv2d)\n",
              "     (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "   )\n",
              "   (2): RecursiveScriptModule(\n",
              "     original_name=Block35\n",
              "     (branch0): RecursiveScriptModule(\n",
              "       original_name=BasicConv2d\n",
              "       (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "       (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "       (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "     )\n",
              "     (branch1): RecursiveScriptModule(\n",
              "       original_name=Sequential\n",
              "       (0): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "       (1): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "     )\n",
              "     (branch2): RecursiveScriptModule(\n",
              "       original_name=Sequential\n",
              "       (0): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "       (1): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "       (2): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "     )\n",
              "     (conv2d): RecursiveScriptModule(original_name=Conv2d)\n",
              "     (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "   )\n",
              "   (3): RecursiveScriptModule(\n",
              "     original_name=Block35\n",
              "     (branch0): RecursiveScriptModule(\n",
              "       original_name=BasicConv2d\n",
              "       (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "       (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "       (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "     )\n",
              "     (branch1): RecursiveScriptModule(\n",
              "       original_name=Sequential\n",
              "       (0): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "       (1): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "     )\n",
              "     (branch2): RecursiveScriptModule(\n",
              "       original_name=Sequential\n",
              "       (0): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "       (1): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "       (2): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "     )\n",
              "     (conv2d): RecursiveScriptModule(original_name=Conv2d)\n",
              "     (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "   )\n",
              "   (4): RecursiveScriptModule(\n",
              "     original_name=Block35\n",
              "     (branch0): RecursiveScriptModule(\n",
              "       original_name=BasicConv2d\n",
              "       (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "       (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "       (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "     )\n",
              "     (branch1): RecursiveScriptModule(\n",
              "       original_name=Sequential\n",
              "       (0): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "       (1): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "     )\n",
              "     (branch2): RecursiveScriptModule(\n",
              "       original_name=Sequential\n",
              "       (0): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "       (1): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "       (2): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "     )\n",
              "     (conv2d): RecursiveScriptModule(original_name=Conv2d)\n",
              "     (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "   )\n",
              " ), RecursiveScriptModule(\n",
              "   original_name=Mixed_6a\n",
              "   (branch0): RecursiveScriptModule(\n",
              "     original_name=BasicConv2d\n",
              "     (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "     (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "     (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "   )\n",
              "   (branch1): RecursiveScriptModule(\n",
              "     original_name=Sequential\n",
              "     (0): RecursiveScriptModule(\n",
              "       original_name=BasicConv2d\n",
              "       (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "       (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "       (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "     )\n",
              "     (1): RecursiveScriptModule(\n",
              "       original_name=BasicConv2d\n",
              "       (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "       (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "       (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "     )\n",
              "     (2): RecursiveScriptModule(\n",
              "       original_name=BasicConv2d\n",
              "       (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "       (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "       (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "     )\n",
              "   )\n",
              "   (branch2): RecursiveScriptModule(original_name=MaxPool2d)\n",
              " ), RecursiveScriptModule(\n",
              "   original_name=Sequential\n",
              "   (0): RecursiveScriptModule(\n",
              "     original_name=Block17\n",
              "     (branch0): RecursiveScriptModule(\n",
              "       original_name=BasicConv2d\n",
              "       (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "       (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "       (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "     )\n",
              "     (branch1): RecursiveScriptModule(\n",
              "       original_name=Sequential\n",
              "       (0): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "       (1): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "       (2): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "     )\n",
              "     (conv2d): RecursiveScriptModule(original_name=Conv2d)\n",
              "     (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "   )\n",
              "   (1): RecursiveScriptModule(\n",
              "     original_name=Block17\n",
              "     (branch0): RecursiveScriptModule(\n",
              "       original_name=BasicConv2d\n",
              "       (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "       (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "       (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "     )\n",
              "     (branch1): RecursiveScriptModule(\n",
              "       original_name=Sequential\n",
              "       (0): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "       (1): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "       (2): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "     )\n",
              "     (conv2d): RecursiveScriptModule(original_name=Conv2d)\n",
              "     (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "   )\n",
              "   (2): RecursiveScriptModule(\n",
              "     original_name=Block17\n",
              "     (branch0): RecursiveScriptModule(\n",
              "       original_name=BasicConv2d\n",
              "       (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "       (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "       (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "     )\n",
              "     (branch1): RecursiveScriptModule(\n",
              "       original_name=Sequential\n",
              "       (0): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "       (1): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "       (2): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "     )\n",
              "     (conv2d): RecursiveScriptModule(original_name=Conv2d)\n",
              "     (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "   )\n",
              "   (3): RecursiveScriptModule(\n",
              "     original_name=Block17\n",
              "     (branch0): RecursiveScriptModule(\n",
              "       original_name=BasicConv2d\n",
              "       (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "       (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "       (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "     )\n",
              "     (branch1): RecursiveScriptModule(\n",
              "       original_name=Sequential\n",
              "       (0): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "       (1): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "       (2): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "     )\n",
              "     (conv2d): RecursiveScriptModule(original_name=Conv2d)\n",
              "     (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "   )\n",
              "   (4): RecursiveScriptModule(\n",
              "     original_name=Block17\n",
              "     (branch0): RecursiveScriptModule(\n",
              "       original_name=BasicConv2d\n",
              "       (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "       (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "       (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "     )\n",
              "     (branch1): RecursiveScriptModule(\n",
              "       original_name=Sequential\n",
              "       (0): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "       (1): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "       (2): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "     )\n",
              "     (conv2d): RecursiveScriptModule(original_name=Conv2d)\n",
              "     (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "   )\n",
              "   (5): RecursiveScriptModule(\n",
              "     original_name=Block17\n",
              "     (branch0): RecursiveScriptModule(\n",
              "       original_name=BasicConv2d\n",
              "       (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "       (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "       (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "     )\n",
              "     (branch1): RecursiveScriptModule(\n",
              "       original_name=Sequential\n",
              "       (0): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "       (1): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "       (2): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "     )\n",
              "     (conv2d): RecursiveScriptModule(original_name=Conv2d)\n",
              "     (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "   )\n",
              "   (6): RecursiveScriptModule(\n",
              "     original_name=Block17\n",
              "     (branch0): RecursiveScriptModule(\n",
              "       original_name=BasicConv2d\n",
              "       (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "       (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "       (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "     )\n",
              "     (branch1): RecursiveScriptModule(\n",
              "       original_name=Sequential\n",
              "       (0): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "       (1): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "       (2): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "     )\n",
              "     (conv2d): RecursiveScriptModule(original_name=Conv2d)\n",
              "     (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "   )\n",
              "   (7): RecursiveScriptModule(\n",
              "     original_name=Block17\n",
              "     (branch0): RecursiveScriptModule(\n",
              "       original_name=BasicConv2d\n",
              "       (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "       (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "       (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "     )\n",
              "     (branch1): RecursiveScriptModule(\n",
              "       original_name=Sequential\n",
              "       (0): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "       (1): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "       (2): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "     )\n",
              "     (conv2d): RecursiveScriptModule(original_name=Conv2d)\n",
              "     (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "   )\n",
              "   (8): RecursiveScriptModule(\n",
              "     original_name=Block17\n",
              "     (branch0): RecursiveScriptModule(\n",
              "       original_name=BasicConv2d\n",
              "       (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "       (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "       (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "     )\n",
              "     (branch1): RecursiveScriptModule(\n",
              "       original_name=Sequential\n",
              "       (0): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "       (1): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "       (2): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "     )\n",
              "     (conv2d): RecursiveScriptModule(original_name=Conv2d)\n",
              "     (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "   )\n",
              "   (9): RecursiveScriptModule(\n",
              "     original_name=Block17\n",
              "     (branch0): RecursiveScriptModule(\n",
              "       original_name=BasicConv2d\n",
              "       (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "       (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "       (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "     )\n",
              "     (branch1): RecursiveScriptModule(\n",
              "       original_name=Sequential\n",
              "       (0): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "       (1): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "       (2): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "     )\n",
              "     (conv2d): RecursiveScriptModule(original_name=Conv2d)\n",
              "     (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "   )\n",
              " ), RecursiveScriptModule(\n",
              "   original_name=Mixed_7a\n",
              "   (branch0): RecursiveScriptModule(\n",
              "     original_name=Sequential\n",
              "     (0): RecursiveScriptModule(\n",
              "       original_name=BasicConv2d\n",
              "       (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "       (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "       (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "     )\n",
              "     (1): RecursiveScriptModule(\n",
              "       original_name=BasicConv2d\n",
              "       (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "       (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "       (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "     )\n",
              "   )\n",
              "   (branch1): RecursiveScriptModule(\n",
              "     original_name=Sequential\n",
              "     (0): RecursiveScriptModule(\n",
              "       original_name=BasicConv2d\n",
              "       (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "       (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "       (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "     )\n",
              "     (1): RecursiveScriptModule(\n",
              "       original_name=BasicConv2d\n",
              "       (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "       (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "       (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "     )\n",
              "   )\n",
              "   (branch2): RecursiveScriptModule(\n",
              "     original_name=Sequential\n",
              "     (0): RecursiveScriptModule(\n",
              "       original_name=BasicConv2d\n",
              "       (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "       (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "       (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "     )\n",
              "     (1): RecursiveScriptModule(\n",
              "       original_name=BasicConv2d\n",
              "       (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "       (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "       (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "     )\n",
              "     (2): RecursiveScriptModule(\n",
              "       original_name=BasicConv2d\n",
              "       (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "       (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "       (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "     )\n",
              "   )\n",
              "   (branch3): RecursiveScriptModule(original_name=MaxPool2d)\n",
              " ), RecursiveScriptModule(\n",
              "   original_name=Sequential\n",
              "   (0): RecursiveScriptModule(\n",
              "     original_name=Block8\n",
              "     (branch0): RecursiveScriptModule(\n",
              "       original_name=BasicConv2d\n",
              "       (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "       (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "       (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "     )\n",
              "     (branch1): RecursiveScriptModule(\n",
              "       original_name=Sequential\n",
              "       (0): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "       (1): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "       (2): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "     )\n",
              "     (conv2d): RecursiveScriptModule(original_name=Conv2d)\n",
              "     (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "   )\n",
              "   (1): RecursiveScriptModule(\n",
              "     original_name=Block8\n",
              "     (branch0): RecursiveScriptModule(\n",
              "       original_name=BasicConv2d\n",
              "       (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "       (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "       (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "     )\n",
              "     (branch1): RecursiveScriptModule(\n",
              "       original_name=Sequential\n",
              "       (0): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "       (1): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "       (2): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "     )\n",
              "     (conv2d): RecursiveScriptModule(original_name=Conv2d)\n",
              "     (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "   )\n",
              "   (2): RecursiveScriptModule(\n",
              "     original_name=Block8\n",
              "     (branch0): RecursiveScriptModule(\n",
              "       original_name=BasicConv2d\n",
              "       (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "       (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "       (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "     )\n",
              "     (branch1): RecursiveScriptModule(\n",
              "       original_name=Sequential\n",
              "       (0): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "       (1): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "       (2): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "     )\n",
              "     (conv2d): RecursiveScriptModule(original_name=Conv2d)\n",
              "     (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "   )\n",
              "   (3): RecursiveScriptModule(\n",
              "     original_name=Block8\n",
              "     (branch0): RecursiveScriptModule(\n",
              "       original_name=BasicConv2d\n",
              "       (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "       (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "       (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "     )\n",
              "     (branch1): RecursiveScriptModule(\n",
              "       original_name=Sequential\n",
              "       (0): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "       (1): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "       (2): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "     )\n",
              "     (conv2d): RecursiveScriptModule(original_name=Conv2d)\n",
              "     (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "   )\n",
              "   (4): RecursiveScriptModule(\n",
              "     original_name=Block8\n",
              "     (branch0): RecursiveScriptModule(\n",
              "       original_name=BasicConv2d\n",
              "       (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "       (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "       (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "     )\n",
              "     (branch1): RecursiveScriptModule(\n",
              "       original_name=Sequential\n",
              "       (0): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "       (1): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "       (2): RecursiveScriptModule(\n",
              "         original_name=BasicConv2d\n",
              "         (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "         (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "         (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "       )\n",
              "     )\n",
              "     (conv2d): RecursiveScriptModule(original_name=Conv2d)\n",
              "     (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "   )\n",
              " ), RecursiveScriptModule(\n",
              "   original_name=Block8\n",
              "   (branch0): RecursiveScriptModule(\n",
              "     original_name=BasicConv2d\n",
              "     (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "     (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "     (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "   )\n",
              "   (branch1): RecursiveScriptModule(\n",
              "     original_name=Sequential\n",
              "     (0): RecursiveScriptModule(\n",
              "       original_name=BasicConv2d\n",
              "       (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "       (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "       (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "     )\n",
              "     (1): RecursiveScriptModule(\n",
              "       original_name=BasicConv2d\n",
              "       (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "       (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "       (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "     )\n",
              "     (2): RecursiveScriptModule(\n",
              "       original_name=BasicConv2d\n",
              "       (conv): RecursiveScriptModule(original_name=Conv2d)\n",
              "       (bn): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "       (relu): RecursiveScriptModule(original_name=ReLU)\n",
              "     )\n",
              "   )\n",
              "   (conv2d): RecursiveScriptModule(original_name=Conv2d)\n",
              " ), RecursiveScriptModule(original_name=AdaptiveAvgPool2d), RecursiveScriptModule(\n",
              "   original_name=Sequential\n",
              "   (0): RecursiveScriptModule(original_name=Flatten)\n",
              "   (1): RecursiveScriptModule(original_name=Linear)\n",
              "   (2): RecursiveScriptModule(original_name=normalize)\n",
              " ), RecursiveScriptModule(original_name=Linear), RecursiveScriptModule(original_name=Softmax)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7oNuhQwWs2X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uA3hHU5SW4Ak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 46,
      "outputs": []
    }
  ]
}